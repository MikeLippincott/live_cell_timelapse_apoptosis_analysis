{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_wells_path = pathlib.Path(\n",
    "    \"../data_splits/train_test_wells.parquet\"\n",
    ").resolve()\n",
    "\n",
    "predictions_save_path = pathlib.Path(\n",
    "    \"../results/predicted_terminal_profiles_from_all_time_points.parquet\"\n",
    ").resolve()\n",
    "\n",
    "profile_data_path = pathlib.Path(\n",
    "    \"../../data/CP_scDINO_features/combined_CP_scDINO_norm_fs_aggregated.parquet\"\n",
    ").resolve()\n",
    "terminal_column_names = pathlib.Path(\"../results/terminal_columns.txt\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "terminal_column_names = [\n",
    "    line.strip() for line in terminal_column_names.read_text().splitlines()\n",
    "]\n",
    "models_path = pathlib.Path(\"../models\").resolve()\n",
    "data_split_df = pd.read_parquet(train_test_wells_path)\n",
    "df = pd.read_parquet(profile_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pathlib.Path(models_path).glob(\"*.joblib\")\n",
    "models_dict = {\n",
    "    \"model_name\": [],\n",
    "    \"model_path\": [],\n",
    "    \"shuffled\": [],\n",
    "    \"feature\": [],\n",
    "}\n",
    "\n",
    "for model_path in models:\n",
    "    models_dict[\"model_name\"].append(model_path.name)\n",
    "    models_dict[\"model_path\"].append(model_path)\n",
    "    models_dict[\"shuffled\"].append(\n",
    "        \"shuffled\" if \"shuffled\" in model_path.name else \"not_shuffled\"\n",
    "    )\n",
    "    models_dict[\"feature\"].append(\n",
    "        \"Terminal_Cytoplasm_Intensity_IntegratedIntensity_AnnexinV\"\n",
    "        if \"terminal_feature\" in model_path.name\n",
    "        else \"all_terminal_features\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train', 'test'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the train/test wells to the aggregate data\n",
    "df[\"Metadata_data_split\"] = df[\"Metadata_Well\"].map(\n",
    "    data_split_df.set_index(\"Metadata_Well\")[\"data_split\"]\n",
    ")\n",
    "data_split = df.pop(\"Metadata_data_split\")\n",
    "df.insert(0, \"Metadata_data_split\", data_split)\n",
    "df[\"Metadata_Time\"] = df[\"Metadata_Time\"].astype(float)\n",
    "# drop NaN values in the terminal columns\n",
    "df = df.dropna(subset=\"Metadata_data_split\")\n",
    "df[\"Metadata_data_split\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the data_split is train and the time is not 12 then set to non_trained_pair\n",
    "# where 12 is the last time point\n",
    "df[\"Metadata_data_split\"] = df.apply(\n",
    "    lambda x: (\n",
    "        \"non_trained_pair\"\n",
    "        if (x[\"Metadata_data_split\"] == \"train\" and x[\"Metadata_Time\"] != 12.0)\n",
    "        else x[\"Metadata_data_split\"]\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_columns = [x for x in df.columns if \"metadata\" in x.lower()]\n",
    "aggregate_features_df = df.drop(columns=metadata_columns, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lippincm/miniforge3/envs/nf1_image_based_profiling_env/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ElasticNetCV from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lippincm/miniforge3/envs/nf1_image_based_profiling_env/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ElasticNetCV from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lippincm/miniforge3/envs/nf1_image_based_profiling_env/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ElasticNetCV from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminal_Cytoplasm_Intensity_IntegratedIntensity_AnnexinV\n",
      "(390, 10)\n",
      "Terminal_Cytoplasm_Intensity_IntegratedIntensity_AnnexinV\n",
      "(780, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lippincm/miniforge3/envs/nf1_image_based_profiling_env/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MultiOutputRegressor from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_terminal_features\n",
      "(390, 519)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lippincm/miniforge3/envs/nf1_image_based_profiling_env/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator ElasticNetCV from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/home/lippincm/miniforge3/envs/nf1_image_based_profiling_env/lib/python3.12/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MultiOutputRegressor from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_terminal_features\n",
      "(780, 519)\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for i, model_name in enumerate(models_dict[\"feature\"]):\n",
    "    model = joblib.load(models_dict[\"model_path\"][i])\n",
    "    if models_dict[\"feature\"][i] != \"all_terminal_features\":\n",
    "        print(models_dict[\"feature\"][i])\n",
    "        predicted_df = pd.DataFrame(\n",
    "            model.predict(aggregate_features_df),\n",
    "            columns=[models_dict[\"feature\"][i]],\n",
    "        )\n",
    "    else:\n",
    "        print(\"all_terminal_features\")\n",
    "        predicted_df = pd.DataFrame(\n",
    "            model.predict(aggregate_features_df),\n",
    "            columns=terminal_column_names,\n",
    "        )\n",
    "    predicted_df[metadata_columns] = df[metadata_columns]\n",
    "    predicted_df[\"shuffled\"] = models_dict[\"shuffled\"][i]\n",
    "    # drop nan value\n",
    "    predicted_df = predicted_df.dropna()\n",
    "\n",
    "    # check if a key for the feature already exists in results_dict\n",
    "    if f\"{models_dict['feature'][i]}\" in results_dict:\n",
    "        temporary_df = pd.concat(\n",
    "            [results_dict[f\"{models_dict['feature'][i]}\"], predicted_df],\n",
    "            ignore_index=True,\n",
    "            sort=False,\n",
    "        )\n",
    "        results_dict[f\"{models_dict['feature'][i]}\"] = temporary_df\n",
    "    else:\n",
    "        results_dict[f\"{models_dict['feature'][i]}\"] = predicted_df\n",
    "\n",
    "    print(results_dict[f\"{models_dict['feature'][i]}\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in results_dict.keys():\n",
    "    save_path = pathlib.Path(f\"../results/{model}.parquet\").resolve()\n",
    "    save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    results_dict[model].to_parquet(save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_map_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
