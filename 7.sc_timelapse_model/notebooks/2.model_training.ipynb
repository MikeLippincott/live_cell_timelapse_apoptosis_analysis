{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6948e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import (\n",
    "    explained_variance_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3985ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Shuffle the data in the DataFrame.\n",
    "    \"\"\"\n",
    "    df_shuffled = df.copy()\n",
    "    for col in df_shuffled.columns:\n",
    "        # permute the columns\n",
    "        df_shuffled[col] = np.random.permutation(df_shuffled[col])\n",
    "    return df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ee95834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_profile shape: (188065, 2381)\n",
      "sc_endpoint_profile shape: (5767, 545)\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "sc_file_path = pathlib.Path(\"../results/cleaned_sc_profile.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "sc_endpoint_file_path = pathlib.Path(\n",
    "    \"../results/cleaned_endpoint_sc_profile.parquet\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "train_test_wells_file_path = pathlib.Path(\n",
    "    \"../../5.bulk_timelapse_model/data_splits/train_test_wells.parquet\"\n",
    ").resolve(strict=True)\n",
    "model_dir = pathlib.Path(\"../models\").resolve()\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "sc_profile = pd.read_parquet(sc_file_path)\n",
    "sc_endpoint_profile = pd.read_parquet(sc_endpoint_file_path)\n",
    "train_test_wells = pd.read_parquet(train_test_wells_file_path)\n",
    "print(f\"sc_profile shape: {sc_profile.shape}\")\n",
    "print(f\"sc_endpoint_profile shape: {sc_endpoint_profile.shape}\")\n",
    "data_split_file_path = pathlib.Path(\"../results/data_splits.parquet\").resolve()\n",
    "data_splits = pd.read_parquet(data_split_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4e0066ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data\n",
    "training_df_X = sc_profile.iloc[\n",
    "    data_splits[\"index\"][data_splits[\"data_split\"] == \"train\"]\n",
    "]\n",
    "training_df_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        training_df_X[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "]\n",
    "assert (\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].nunique()\n",
    "    == training_df_y[\"Metadata_sc_unique_track_id\"].nunique()\n",
    ")\n",
    "training_df_X_shuffled = training_df_X.copy()\n",
    "training_df_X_shuffled = shuffle_data(training_df_X_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6ac2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_metadata = [x for x in training_df_X.columns if \"Metadata\" in x]\n",
    "train_y_metadata = [y for y in training_df_y.columns if \"Metadata\" in y]\n",
    "training_X_features = [x for x in training_df_X.columns if x not in train_x_metadata]\n",
    "training_y_features = [y for y in training_df_y.columns if y not in train_y_metadata]\n",
    "\n",
    "train_x_shuffled_metadata = [\n",
    "    x for x in training_df_X_shuffled.columns if \"Metadata\" in x\n",
    "]\n",
    "train_y_shuffled_metadata = [y for y in training_df_y.columns if \"Metadata\" in y]\n",
    "train_x_shuffled_features = [\n",
    "    x for x in training_df_X_shuffled.columns if x not in train_x_shuffled_metadata\n",
    "]\n",
    "\n",
    "train_df_x_metadata = training_df_X[train_x_metadata]\n",
    "train_df_y_metadata = training_df_y[train_y_metadata]\n",
    "train_df_x_features = training_df_X[training_X_features]\n",
    "train_df_y_features = training_df_y[training_y_features]\n",
    "train_df_x_shuffled_metadata = training_df_X_shuffled[train_x_shuffled_metadata]\n",
    "train_df_x_shuffled_features = training_df_X_shuffled[train_x_shuffled_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a9a513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annexin_feature = \"Cytoplasm_Intensity_IntegratedIntensity_AnnexinV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "af9682f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)  # 5-fold cross-validation\n",
    "# elastic net parameters\n",
    "elastic_net_params = {\n",
    "    \"alpha\": [0.1, 1.0, 10.0, 100.0, 1000.0],  # Regularization strength\n",
    "    \"l1_ratio\": [0.1, 0.25, 0.5, 0.75, 1.0],  # l1_ratio = 1.0 is Lasso\n",
    "    \"max_iter\": 10000,  # Increase max_iter for convergence\n",
    "}\n",
    "elastic_net_all_annexinv_features_model = MultiOutputRegressor(\n",
    "    ElasticNetCV(\n",
    "        alphas=elastic_net_params[\"alpha\"],\n",
    "        l1_ratio=elastic_net_params[\"l1_ratio\"],\n",
    "        cv=cv,\n",
    "        random_state=0,\n",
    "        max_iter=elastic_net_params[\"max_iter\"],\n",
    "    )\n",
    ")\n",
    "elastic_net_all_annexinv_features_model_shuffled = (\n",
    "    elastic_net_all_annexinv_features_model\n",
    ")\n",
    "elastic_net_single_terminal_features_model = ElasticNetCV(\n",
    "    alphas=elastic_net_params[\"alpha\"],\n",
    "    l1_ratio=elastic_net_params[\"l1_ratio\"],\n",
    "    cv=cv,\n",
    "    random_state=0,\n",
    "    max_iter=elastic_net_params[\"max_iter\"],\n",
    ")\n",
    "elastic_net_single_terminal_features_model_shuffled = (\n",
    "    elastic_net_single_terminal_features_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18d8ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_train_tests = {\n",
    "    \"single_feature\": {\n",
    "        \"train\": {\n",
    "            \"X\": train_df_x_features,\n",
    "            \"y\": train_df_y_features[annexin_feature],\n",
    "            \"x_metadata\": train_df_x_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_single_terminal_features_model,\n",
    "            \"model_name\": \"elastic_net_single_terminal_features_model\",\n",
    "        },\n",
    "        \"train_shuffled\": {\n",
    "            \"X\": train_df_x_shuffled_features,\n",
    "            \"y\": train_df_y_features[annexin_feature],\n",
    "            \"x_metadata\": train_df_x_shuffled_metadata,\n",
    "            \"y_metadata\": train_df_y_features,\n",
    "            \"model\": elastic_net_single_terminal_features_model_shuffled,\n",
    "            \"model_name\": \"elastic_net_single_terminal_features_model_shuffled\",\n",
    "        },\n",
    "    },\n",
    "    \"annexinV_features\": {\n",
    "        \"train\": {\n",
    "            \"X\": train_df_x_features,\n",
    "            \"y\": train_df_y_features,\n",
    "            \"x_metadata\": train_df_x_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_all_annexinv_features_model,\n",
    "            \"model_name\": \"elastic_net_all_annexinv_features_model\",\n",
    "        },\n",
    "        \"train_shuffled\": {\n",
    "            \"X\": train_df_x_shuffled_features,\n",
    "            \"y\": train_df_y_features,\n",
    "            \"x_metadata\": train_df_x_shuffled_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_all_annexinv_features_model_shuffled,\n",
    "            \"model_name\": \"elastic_net_all_annexinv_features_model_shuffled\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9d44e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train...single_feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m X \u001b[38;5;241m=\u001b[39m train_test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     11\u001b[0m y \u001b[38;5;241m=\u001b[39m train_test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m metadata \u001b[38;5;241m=\u001b[39m train_test_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, y shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, metadata shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetadata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "\u001b[0;31mKeyError\u001b[0m: 'metadata'"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for model_type in dict_of_train_tests.keys():\n",
    "    for train_test_key, train_test_data in tqdm.tqdm(\n",
    "        dict_of_train_tests[model_type].items()\n",
    "    ):\n",
    "        if \"test\" in train_test_key:\n",
    "            print(f\"Skipping {train_test_key} as it is a test set.\")\n",
    "            continue\n",
    "        print(f\"Training model for {train_test_key}...{model_type}\")\n",
    "        X = train_test_data[\"X\"]\n",
    "        y = train_test_data[\"y\"]\n",
    "        metadata = train_test_data[\"metadata\"]\n",
    "        print(\n",
    "            f\"X shape: {X.shape}, y shape: {y.shape}, metadata shape: {metadata.shape}\"\n",
    "        )\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            train_test_data[\"model\"].fit(X, y)\n",
    "\n",
    "        # save the model\n",
    "        model_path = (\n",
    "            model_dir / f\"{train_test_key}_{train_test_data['model_name']}.joblib\"\n",
    "        )\n",
    "        joblib.dump(train_test_data[\"model\"], model_path)\n",
    "        dict_of_train_tests[model_type][train_test_key][\"model_path\"] = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4308ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 129.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping train as it is a training set.\n",
      "Skipping train_shuffled as it is a training set.\n",
      "single_feature test\n",
      "single_feature test_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping train as it is a training set.\n",
      "Skipping train_shuffled as it is a training set.\n",
      "annexinV_features test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:02<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters for test:\n",
      "Alphas: 0.1, L1 Ratios: 0.1\n",
      "annexinV_features test_shuffled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:13<00:00,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters for test_shuffled:\n",
      "Alphas: 1000.0, L1 Ratios: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "for model_type in dict_of_train_tests.keys():\n",
    "    for train_test_key, train_test_data in tqdm.tqdm(\n",
    "        dict_of_train_tests[model_type].items()\n",
    "    ):\n",
    "        if \"train\" in train_test_key:\n",
    "            print(f\"Skipping {train_test_key} as it is a training set.\")\n",
    "            continue\n",
    "        print(model_type, train_test_key)\n",
    "        X = train_test_data[\"X\"]\n",
    "        y = train_test_data[\"y\"]\n",
    "        metadata = train_test_data[\"metadata\"]\n",
    "        if \"shuffled\" in train_test_key:\n",
    "            model_path = dict_of_train_tests[model_type][\"train_shuffled\"][\"model_path\"]\n",
    "        else:\n",
    "            model_path = dict_of_train_tests[model_type][\"train\"][\"model_path\"]\n",
    "\n",
    "        # load the model\n",
    "        model = joblib.load(model_path)\n",
    "\n",
    "        # make predictions\n",
    "        y_pred = model.predict(X)\n",
    "        if model_type == \"single_feature\":\n",
    "            model.alpha_\n",
    "            model.l1_ratio_\n",
    "        else:\n",
    "\n",
    "            alphas = model.estimators_[0].alpha_\n",
    "            l1_ratios = model.estimators_[0].l1_ratio_\n",
    "            print(f\"Model parameters for {train_test_key}:\")\n",
    "            print(f\"Alphas: {alphas}, L1 Ratios: {l1_ratios}\")\n",
    "\n",
    "        # calculate metrics\n",
    "        metrics = {\n",
    "            \"explained_variance\": explained_variance_score(y, y_pred),\n",
    "            \"mean_absolute_error\": mean_absolute_error(y, y_pred),\n",
    "            \"mean_squared_error\": mean_squared_error(y, y_pred),\n",
    "            \"r2_score\": r2_score(y, y_pred),\n",
    "        }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_analaysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
