{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6948e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import (\n",
    "    explained_variance_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3985ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Shuffle the data in the DataFrame.\n",
    "    \"\"\"\n",
    "    df_shuffled = df.copy()\n",
    "    for col in df_shuffled.columns:\n",
    "        if \"metadata\" in col.lower():\n",
    "            continue  # skip metadata columns\n",
    "        # permute the columns\n",
    "        df_shuffled[col] = np.random.permutation(df_shuffled[col])\n",
    "    return df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee95834e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data\n",
    "sc_file_path = pathlib.Path(\"../results/train_sc_profile.parquet\").resolve(strict=True)\n",
    "sc_endpoint_file_path = pathlib.Path(\n",
    "    \"../results/train_sc_profile_terminal_time.parquet\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "model_dir = pathlib.Path(\"../models\").resolve()\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir = pathlib.Path(\"../results\").resolve()\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "sc_profile = pd.read_parquet(sc_file_path)\n",
    "sc_endpoint_profile = pd.read_parquet(sc_endpoint_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d5ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df_X =\n",
    "training_df_X = sc_profile.loc[\n",
    "    sc_profile[\"Metadata_Time\"] == sc_profile[\"Metadata_Time\"].max()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60c914ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_df_X shape: (2300, 2379) 2300\n",
      "training_df_y shape: (2300, 541) 2300\n"
     ]
    }
   ],
   "source": [
    "training_df_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        training_df_X[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "]\n",
    "print(\n",
    "    f\"training_df_X shape: {training_df_X.shape}\",\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].nunique(),\n",
    ")\n",
    "print(\n",
    "    f\"training_df_y shape: {training_df_y.shape}\",\n",
    "    training_df_y[\"Metadata_sc_unique_track_id\"].nunique(),\n",
    ")\n",
    "assert (\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].nunique()\n",
    "    == training_df_y[\"Metadata_sc_unique_track_id\"].nunique()\n",
    ")\n",
    "assert (\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].shape[0]\n",
    "    == training_df_y[\"Metadata_sc_unique_track_id\"].shape[0]\n",
    ")\n",
    "training_df_X_shuffled = training_df_X.copy()\n",
    "training_df_X_shuffled = shuffle_data(training_df_X_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ac2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_metadata = [x for x in training_df_X.columns if \"Metadata\" in x]\n",
    "train_y_metadata = [y for y in training_df_y.columns if \"Metadata\" in y]\n",
    "training_X_features = [x for x in training_df_X.columns if x not in train_x_metadata]\n",
    "training_y_features = [y for y in training_df_y.columns if y not in train_y_metadata]\n",
    "\n",
    "train_x_shuffled_metadata = [\n",
    "    x for x in training_df_X_shuffled.columns if \"Metadata\" in x\n",
    "]\n",
    "train_y_shuffled_metadata = [y for y in training_df_y.columns if \"Metadata\" in y]\n",
    "train_x_shuffled_features = [\n",
    "    x for x in training_df_X_shuffled.columns if x not in train_x_shuffled_metadata\n",
    "]\n",
    "\n",
    "train_df_x_metadata = training_df_X[train_x_metadata]\n",
    "train_df_y_metadata = training_df_y[train_y_metadata]\n",
    "train_df_x_features = training_df_X[training_X_features]\n",
    "train_df_y_features = training_df_y[training_y_features]\n",
    "train_df_x_shuffled_metadata = training_df_X_shuffled[train_x_shuffled_metadata]\n",
    "train_df_x_shuffled_features = training_df_X_shuffled[train_x_shuffled_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a9a513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annexin_feature = \"Cytoplasm_Intensity_IntegratedIntensity_AnnexinV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af9682f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)  # 5-fold cross-validation\n",
    "# elastic net parameters\n",
    "elastic_net_params = {\n",
    "    \"alpha\": [0.1, 1.0, 10.0, 100.0, 1000.0],  # Regularization strength\n",
    "    \"l1_ratio\": [0.1, 0.25, 0.5, 0.75, 1.0],  # l1_ratio = 1.0 is Lasso\n",
    "    \"max_iter\": 10000,  # Increase max_iter for convergence\n",
    "}\n",
    "elastic_net_all_annexinv_features_model = MultiOutputRegressor(\n",
    "    ElasticNetCV(\n",
    "        alphas=elastic_net_params[\"alpha\"],\n",
    "        l1_ratio=elastic_net_params[\"l1_ratio\"],\n",
    "        cv=cv,\n",
    "        random_state=0,\n",
    "        max_iter=elastic_net_params[\"max_iter\"],\n",
    "    )\n",
    ")\n",
    "elastic_net_all_annexinv_features_model_shuffled = (\n",
    "    elastic_net_all_annexinv_features_model\n",
    ")\n",
    "elastic_net_single_terminal_features_model = ElasticNetCV(\n",
    "    alphas=elastic_net_params[\"alpha\"],\n",
    "    l1_ratio=elastic_net_params[\"l1_ratio\"],\n",
    "    cv=cv,\n",
    "    random_state=0,\n",
    "    max_iter=elastic_net_params[\"max_iter\"],\n",
    ")\n",
    "elastic_net_single_terminal_features_model_shuffled = (\n",
    "    elastic_net_single_terminal_features_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d8ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_train_tests = {\n",
    "    \"single_feature\": {\n",
    "        \"train\": {\n",
    "            \"X\": train_df_x_features,\n",
    "            \"y\": train_df_y_features[annexin_feature],\n",
    "            \"x_metadata\": train_df_x_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_single_terminal_features_model,\n",
    "            \"model_name\": \"elastic_net_single_terminal_features_model\",\n",
    "        },\n",
    "        \"train_shuffled\": {\n",
    "            \"X\": train_df_x_shuffled_features,\n",
    "            \"y\": train_df_y_features[annexin_feature],\n",
    "            \"x_metadata\": train_df_x_shuffled_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_single_terminal_features_model_shuffled,\n",
    "            \"model_name\": \"elastic_net_single_terminal_features_model_shuffled\",\n",
    "        },\n",
    "    },\n",
    "    \"annexinV_features\": {\n",
    "        \"train\": {\n",
    "            \"X\": train_df_x_features,\n",
    "            \"y\": train_df_y_features,\n",
    "            \"x_metadata\": train_df_x_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_all_annexinv_features_model,\n",
    "            \"model_name\": \"elastic_net_all_annexinv_features_model\",\n",
    "        },\n",
    "        \"train_shuffled\": {\n",
    "            \"X\": train_df_x_shuffled_features,\n",
    "            \"y\": train_df_y_features,\n",
    "            \"x_metadata\": train_df_x_shuffled_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_all_annexinv_features_model_shuffled,\n",
    "            \"model_name\": \"elastic_net_all_annexinv_features_model_shuffled\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d44e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train...single_feature\n",
      "X shape: (2300, 2336), y shape: (2300,), x_metadata shape: (2300, 43), y_metadata shape: (2300, 31)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:26<00:26, 26.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train_shuffled...single_feature\n",
      "X shape: (2300, 2336), y shape: (2300,), x_metadata shape: (2300, 43), y_metadata shape: (2300, 31)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:44<00:00, 22.34s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train...annexinV_features\n",
      "X shape: (2300, 2336), y shape: (2300, 510), x_metadata shape: (2300, 43), y_metadata shape: (2300, 31)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [2:00:31<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m     22\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, category\u001b[38;5;241m=\u001b[39mConvergenceWarning)\n\u001b[0;32m---> 23\u001b[0m     dict_of_train_tests[model_type][train_test_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[1;32m     26\u001b[0m model_path \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     27\u001b[0m     model_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_test_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/multioutput.py:274\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.fit\u001b[0;34m(self, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         routed_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)(\n\u001b[1;32m    275\u001b[0m     delayed(_fit_estimator)(\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y[:, i], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit\n\u001b[1;32m    277\u001b[0m     )\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_features_in_\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/multioutput.py:63\u001b[0m, in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight, **fit_params)\u001b[0m\n\u001b[1;32m     61\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:2405\u001b[0m, in \u001b[0;36mElasticNetCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   2367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m   2368\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit ElasticNet model with coordinate descent.\u001b[39;00m\n\u001b[1;32m   2369\u001b[0m \n\u001b[1;32m   2370\u001b[0m \u001b[38;5;124;03m    Fit is on grid of alphas and best alpha estimated by cross-validation.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2403\u001b[0m \u001b[38;5;124;03m        Returns an instance of fitted model.\u001b[39;00m\n\u001b[1;32m   2404\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1793\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;66;03m# We do a double for loop folded in one, in order to be able to\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;66;03m# iterate in parallel on l1_ratio and folds\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m jobs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1776\u001b[0m     delayed(_path_residuals)(\n\u001b[1;32m   1777\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[1;32m   1792\u001b[0m )\n\u001b[0;32m-> 1793\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m   1794\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m   1795\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1796\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1797\u001b[0m )(jobs)\n\u001b[1;32m   1798\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mse_paths, (n_l1_ratio, \u001b[38;5;28mlen\u001b[39m(folds), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;66;03m# The mean is computed over folds.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/utils/parallel.py:139\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:1472\u001b[0m, in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, sample_weight, train, test, fit_intercept, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;66;03m# Do the ordering and type casting here, as if it is done in the path,\u001b[39;00m\n\u001b[1;32m   1470\u001b[0m \u001b[38;5;66;03m# X is copied and a reference is kept here\u001b[39;00m\n\u001b[1;32m   1471\u001b[0m X_train \u001b[38;5;241m=\u001b[39m check_array(X_train, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39mX_order)\n\u001b[0;32m-> 1472\u001b[0m alphas, coefs, _ \u001b[38;5;241m=\u001b[39m path(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpath_params)\n\u001b[1;32m   1473\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_train, y_train\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1476\u001b[0m     \u001b[38;5;66;03m# Doing this so that it becomes coherent with multioutput.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:189\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    191\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    681\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    682\u001b[0m         coef_,\n\u001b[1;32m    683\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         positive,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent(\n\u001b[1;32m    696\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[1;32m    697\u001b[0m     )\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    702\u001b[0m     )\n",
      "File \u001b[0;32m_cd_fast.pyx:127\u001b[0m, in \u001b[0;36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/timelapse_analaysis_env/lib/python3.11/site-packages/numpy/core/_methods.py:47\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_amin\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     44\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_minimum(a, axis, \u001b[38;5;28;01mNone\u001b[39;00m, out, keepdims, initial, where)\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_prod\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     52\u001b[0m           initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for model_type in dict_of_train_tests.keys():\n",
    "    for train_test_key, train_test_data in tqdm.tqdm(\n",
    "        dict_of_train_tests[model_type].items()\n",
    "    ):\n",
    "        if \"test\" in train_test_key:\n",
    "            print(f\"Skipping {train_test_key} as it is a test set.\")\n",
    "            continue\n",
    "        print(f\"Training model for {train_test_key}...{model_type}\")\n",
    "        X = train_test_data[\"X\"]\n",
    "        y = train_test_data[\"y\"]\n",
    "        x_metadata = dict_of_train_tests[model_type][train_test_key][\"x_metadata\"]\n",
    "        y_metadata = dict_of_train_tests[model_type][train_test_key][\"y_metadata\"]\n",
    "        print(\n",
    "            f\"X shape: {X.shape}, y shape: {y.shape}, x_metadata shape: {x_metadata.shape}, y_metadata shape: {y_metadata.shape}\"\n",
    "        )\n",
    "        # find the number of NaNs\n",
    "        num_nans_X = X.isna().sum().sum()\n",
    "        num_nans_y = y.isna().sum().sum()\n",
    "        print(f\"Number of NaNs in X: {num_nans_X}, Number of NaNs in y: {num_nans_y}\")\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            dict_of_train_tests[model_type][train_test_key][\"model\"].fit(X, y)\n",
    "\n",
    "        # save the model\n",
    "        model_path = (\n",
    "            model_dir / f\"{train_test_key}_{train_test_data['model_name']}.joblib\"\n",
    "        )\n",
    "        joblib.dump(train_test_data[\"model\"], model_path)\n",
    "        dict_of_train_tests[model_type][train_test_key][\"model_path\"] = model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537c36e",
   "metadata": {},
   "source": [
    "training took approximately 637 minutes (10.6 hours) on a machine with 1 NVIDIA 3090 TI GPU."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_analaysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
