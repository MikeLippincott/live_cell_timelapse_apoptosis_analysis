{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6948e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import warnings\n",
    "from typing import List, Tuple\n",
    "\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import (\n",
    "    explained_variance_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3985ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Shuffle the data in the DataFrame.\n",
    "    \"\"\"\n",
    "    df_shuffled = df.copy()\n",
    "    for col in df_shuffled.columns:\n",
    "        # permute the columns\n",
    "        df_shuffled[col] = np.random.permutation(df_shuffled[col])\n",
    "    return df_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee95834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_profile shape: (185502, 2383)\n",
      "sc_endpoint_profile shape: (4733, 545)\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "sc_file_path = pathlib.Path(\"../results/cleaned_sc_profile.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "sc_endpoint_file_path = pathlib.Path(\n",
    "    \"../results/cleaned_endpoint_sc_profile.parquet\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "train_test_wells_file_path = pathlib.Path(\n",
    "    \"../../5.bulk_timelapse_model/data_splits/train_test_wells.parquet\"\n",
    ").resolve(strict=True)\n",
    "model_dir = pathlib.Path(\"../models\").resolve()\n",
    "model_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir = pathlib.Path(\"../results\").resolve()\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "sc_profile = pd.read_parquet(sc_file_path)\n",
    "sc_endpoint_profile = pd.read_parquet(sc_endpoint_file_path)\n",
    "train_test_wells = pd.read_parquet(train_test_wells_file_path)\n",
    "print(f\"sc_profile shape: {sc_profile.shape}\")\n",
    "print(f\"sc_endpoint_profile shape: {sc_endpoint_profile.shape}\")\n",
    "data_split_file_path = pathlib.Path(\"../results/data_splits.parquet\").resolve()\n",
    "data_splits = pd.read_parquet(data_split_file_path)\n",
    "sc_profile[\"Metadata_Time\"] = sc_profile[\"Metadata_Time\"].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76faeccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_splits shape before filtering: (185502, 3)\n",
      "data_splits shape after filtering: (185502, 3)\n"
     ]
    }
   ],
   "source": [
    "# remove any rows of index that are not in sc_profile\n",
    "print(f\"data_splits shape before filtering: {data_splits.shape}\")\n",
    "data_splits = data_splits[data_splits[\"index\"].isin(sc_profile.index)]\n",
    "print(f\"data_splits shape after filtering: {data_splits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c98a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training data\n",
    "training_df_X = sc_profile.loc[\n",
    "    data_splits[\"index\"][data_splits[\"data_split\"] == \"train\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d5ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df_X =\n",
    "training_df_X = training_df_X.loc[\n",
    "    training_df_X[\"Metadata_Time\"] == training_df_X[\"Metadata_Time\"].max()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c914ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_df_X shape: (2336, 2383) 2336\n",
      "training_df_y shape: (2336, 545) 2336\n"
     ]
    }
   ],
   "source": [
    "training_df_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        training_df_X[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "]\n",
    "print(\n",
    "    f\"training_df_X shape: {training_df_X.shape}\",\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].nunique(),\n",
    ")\n",
    "print(\n",
    "    f\"training_df_y shape: {training_df_y.shape}\",\n",
    "    training_df_y[\"Metadata_sc_unique_track_id\"].nunique(),\n",
    ")\n",
    "assert (\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].nunique()\n",
    "    == training_df_y[\"Metadata_sc_unique_track_id\"].nunique()\n",
    ")\n",
    "assert (\n",
    "    training_df_X[\"Metadata_sc_unique_track_id\"].shape[0]\n",
    "    == training_df_y[\"Metadata_sc_unique_track_id\"].shape[0]\n",
    ")\n",
    "training_df_X_shuffled = training_df_X.copy()\n",
    "training_df_X_shuffled = shuffle_data(training_df_X_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6ac2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_metadata = [x for x in training_df_X.columns if \"Metadata\" in x]\n",
    "train_y_metadata = [y for y in training_df_y.columns if \"Metadata\" in y]\n",
    "training_X_features = [x for x in training_df_X.columns if x not in train_x_metadata]\n",
    "training_y_features = [y for y in training_df_y.columns if y not in train_y_metadata]\n",
    "\n",
    "train_x_shuffled_metadata = [\n",
    "    x for x in training_df_X_shuffled.columns if \"Metadata\" in x\n",
    "]\n",
    "train_y_shuffled_metadata = [y for y in training_df_y.columns if \"Metadata\" in y]\n",
    "train_x_shuffled_features = [\n",
    "    x for x in training_df_X_shuffled.columns if x not in train_x_shuffled_metadata\n",
    "]\n",
    "\n",
    "train_df_x_metadata = training_df_X[train_x_metadata]\n",
    "train_df_y_metadata = training_df_y[train_y_metadata]\n",
    "train_df_x_features = training_df_X[training_X_features]\n",
    "train_df_y_features = training_df_y[training_y_features]\n",
    "train_df_x_shuffled_metadata = training_df_X_shuffled[train_x_shuffled_metadata]\n",
    "train_df_x_shuffled_features = training_df_X_shuffled[train_x_shuffled_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9a513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annexin_feature = \"Cytoplasm_Intensity_IntegratedIntensity_AnnexinV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9682f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)  # 5-fold cross-validation\n",
    "# elastic net parameters\n",
    "elastic_net_params = {\n",
    "    \"alpha\": [0.1, 1.0, 10.0, 100.0, 1000.0],  # Regularization strength\n",
    "    \"l1_ratio\": [0.1, 0.25, 0.5, 0.75, 1.0],  # l1_ratio = 1.0 is Lasso\n",
    "    \"max_iter\": 10000,  # Increase max_iter for convergence\n",
    "}\n",
    "elastic_net_all_annexinv_features_model = MultiOutputRegressor(\n",
    "    ElasticNetCV(\n",
    "        alphas=elastic_net_params[\"alpha\"],\n",
    "        l1_ratio=elastic_net_params[\"l1_ratio\"],\n",
    "        cv=cv,\n",
    "        random_state=0,\n",
    "        max_iter=elastic_net_params[\"max_iter\"],\n",
    "    )\n",
    ")\n",
    "elastic_net_all_annexinv_features_model_shuffled = (\n",
    "    elastic_net_all_annexinv_features_model\n",
    ")\n",
    "elastic_net_single_terminal_features_model = ElasticNetCV(\n",
    "    alphas=elastic_net_params[\"alpha\"],\n",
    "    l1_ratio=elastic_net_params[\"l1_ratio\"],\n",
    "    cv=cv,\n",
    "    random_state=0,\n",
    "    max_iter=elastic_net_params[\"max_iter\"],\n",
    ")\n",
    "elastic_net_single_terminal_features_model_shuffled = (\n",
    "    elastic_net_single_terminal_features_model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18d8ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_train_tests = {\n",
    "    \"single_feature\": {\n",
    "        \"train\": {\n",
    "            \"X\": train_df_x_features,\n",
    "            \"y\": train_df_y_features[annexin_feature],\n",
    "            \"x_metadata\": train_df_x_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_single_terminal_features_model,\n",
    "            \"model_name\": \"elastic_net_single_terminal_features_model\",\n",
    "        },\n",
    "        \"train_shuffled\": {\n",
    "            \"X\": train_df_x_shuffled_features,\n",
    "            \"y\": train_df_y_features[annexin_feature],\n",
    "            \"x_metadata\": train_df_x_shuffled_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_single_terminal_features_model_shuffled,\n",
    "            \"model_name\": \"elastic_net_single_terminal_features_model_shuffled\",\n",
    "        },\n",
    "    },\n",
    "    \"annexinV_features\": {\n",
    "        \"train\": {\n",
    "            \"X\": train_df_x_features,\n",
    "            \"y\": train_df_y_features,\n",
    "            \"x_metadata\": train_df_x_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_all_annexinv_features_model,\n",
    "            \"model_name\": \"elastic_net_all_annexinv_features_model\",\n",
    "        },\n",
    "        \"train_shuffled\": {\n",
    "            \"X\": train_df_x_shuffled_features,\n",
    "            \"y\": train_df_y_features,\n",
    "            \"x_metadata\": train_df_x_shuffled_metadata,\n",
    "            \"y_metadata\": train_df_y_metadata,\n",
    "            \"model\": elastic_net_all_annexinv_features_model_shuffled,\n",
    "            \"model_name\": \"elastic_net_all_annexinv_features_model_shuffled\",\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d44e011",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train...single_feature\n",
      "X shape: (2336, 2336), y shape: (2336,), x_metadata shape: (2336, 47), y_metadata shape: (2336, 35)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:20<00:20, 20.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train_shuffled...single_feature\n",
      "X shape: (2336, 2336), y shape: (2336,), x_metadata shape: (2336, 47), y_metadata shape: (2336, 35)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:37<00:00, 18.89s/it]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train...annexinV_features\n",
      "X shape: (2336, 2336), y shape: (2336, 510), x_metadata shape: (2336, 47), y_metadata shape: (2336, 35)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [2:19:22<2:19:22, 8362.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for train_shuffled...annexinV_features\n",
      "X shape: (2336, 2336), y shape: (2336, 510), x_metadata shape: (2336, 47), y_metadata shape: (2336, 35)\n",
      "Number of NaNs in X: 0, Number of NaNs in y: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [2:53:01<00:00, 5190.71s/it]  \n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "for model_type in dict_of_train_tests.keys():\n",
    "    for train_test_key, train_test_data in tqdm.tqdm(\n",
    "        dict_of_train_tests[model_type].items()\n",
    "    ):\n",
    "        if \"test\" in train_test_key:\n",
    "            print(f\"Skipping {train_test_key} as it is a test set.\")\n",
    "            continue\n",
    "        print(f\"Training model for {train_test_key}...{model_type}\")\n",
    "        X = train_test_data[\"X\"]\n",
    "        y = train_test_data[\"y\"]\n",
    "        x_metadata = dict_of_train_tests[model_type][train_test_key][\"x_metadata\"]\n",
    "        y_metadata = dict_of_train_tests[model_type][train_test_key][\"y_metadata\"]\n",
    "        print(\n",
    "            f\"X shape: {X.shape}, y shape: {y.shape}, x_metadata shape: {x_metadata.shape}, y_metadata shape: {y_metadata.shape}\"\n",
    "        )\n",
    "        # find the number of NaNs\n",
    "        num_nans_X = X.isna().sum().sum()\n",
    "        num_nans_y = y.isna().sum().sum()\n",
    "        print(f\"Number of NaNs in X: {num_nans_X}, Number of NaNs in y: {num_nans_y}\")\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            dict_of_train_tests[model_type][train_test_key][\"model\"].fit(X, y)\n",
    "\n",
    "        # save the model\n",
    "        model_path = (\n",
    "            model_dir / f\"{train_test_key}_{train_test_data['model_name']}.joblib\"\n",
    "        )\n",
    "        joblib.dump(train_test_data[\"model\"], model_path)\n",
    "        dict_of_train_tests[model_type][train_test_key][\"model_path\"] = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cda6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_analaysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
