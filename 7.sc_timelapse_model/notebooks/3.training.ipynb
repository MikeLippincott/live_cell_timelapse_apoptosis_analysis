{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import toml\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../ML_utils/\")\n",
    "\n",
    "from parameter_set import parameter_set\n",
    "from parameters import Parameters\n",
    "from train_optimized_model import train_optimized_model\n",
    "\n",
    "try:\n",
    "    cfg = get_ipython().config\n",
    "    in_notebook = True\n",
    "except NameError:\n",
    "    in_notebook = False\n",
    "if in_notebook:\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_profile shape: (182804, 2376)\n",
      "sc_endpoint_profile shape: (11340, 368)\n",
      "data_split_df shape: (14926, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>data_split</th>\n",
       "      <th>data_x_or_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7440</td>\n",
       "      <td>train_gt</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7461</td>\n",
       "      <td>train_gt</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7463</td>\n",
       "      <td>train_gt</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7468</td>\n",
       "      <td>train_gt</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7479</td>\n",
       "      <td>train_gt</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index data_split data_x_or_y\n",
       "0   7440   train_gt           X\n",
       "1   7461   train_gt           X\n",
       "2   7463   train_gt           X\n",
       "3   7468   train_gt           X\n",
       "4   7479   train_gt           X"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "sc_file_path = pathlib.Path(\"../results/cleaned_sc_profile.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "sc_endpoint_file_path = pathlib.Path(\n",
    "    \"../results/cleaned_endpoint_sc_profile.parquet\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "data_split_file_path = pathlib.Path(\"../results/data_splits.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "\n",
    "sc_profile = pd.read_parquet(sc_file_path)\n",
    "sc_endpoint_profile = pd.read_parquet(sc_endpoint_file_path)\n",
    "data_split_df = pd.read_parquet(data_split_file_path)\n",
    "print(f\"sc_profile shape: {sc_profile.shape}\")\n",
    "print(f\"sc_endpoint_profile shape: {sc_endpoint_profile.shape}\")\n",
    "print(f\"data_split_df shape: {data_split_df.shape}\")\n",
    "data_split_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_profile shape after dropping NaN: (14237, 2376)\n",
      "sc_endpoint_profile shape after dropping NaN: (11136, 368)\n",
      "sc_endpoint_profile shape after selecting features: (11136, 26)\n"
     ]
    }
   ],
   "source": [
    "# keep only the last timepoint\n",
    "sc_profile[\"Metadata_Time\"] = sc_profile[\"Metadata_Time\"].astype(\"float64\")\n",
    "sc_profile = sc_profile[\n",
    "    sc_profile[\"Metadata_Time\"] == sc_profile[\"Metadata_Time\"].max()\n",
    "]\n",
    "# drop Na values\n",
    "sc_profile.dropna(inplace=True)\n",
    "print(f\"sc_profile shape after dropping NaN: {sc_profile.shape}\")\n",
    "sc_endpoint_profile.dropna(inplace=True)\n",
    "print(f\"sc_endpoint_profile shape after dropping NaN: {sc_endpoint_profile.shape}\")\n",
    "# hardcode the features that should exist in the y data\n",
    "# this will be replaced in the future by an arg or config passed through\n",
    "selected_y_features = [\"Cells_Intensity_MeanIntensityEdge_AnnexinV\"]\n",
    "metadata_y_features = [x for x in sc_endpoint_profile.columns if \"Metadata_\" in x]\n",
    "sc_endpoint_profile = sc_endpoint_profile[metadata_y_features + selected_y_features]\n",
    "print(\n",
    "    f\"sc_endpoint_profile shape after selecting features: {sc_endpoint_profile.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data_splits_df = data_split_df.loc[data_split_df[\"data_x_or_y\"] == \"X\"]\n",
    "profile_data_splits_df\n",
    "endpoint_data_splits_df = data_split_df.loc[data_split_df[\"data_x_or_y\"] == \"y\"]\n",
    "endpoint_data_splits_df\n",
    "# replace the index with the index column\n",
    "profile_data_splits_df = profile_data_splits_df.set_index(\n",
    "    \"index\", drop=True, verify_integrity=True\n",
    ")\n",
    "endpoint_data_splits_df = endpoint_data_splits_df.set_index(\n",
    "    \"index\", drop=True, verify_integrity=True\n",
    ")\n",
    "# remove the index name from profile_data_splits_df\n",
    "profile_data_splits_df.index.name = None\n",
    "# remove the index name from endpoint_data_splits_df\n",
    "endpoint_data_splits_df.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only indexes from sc_profile that are in the train_gt split\n",
    "train_gt_X = sc_profile.loc[\n",
    "    sc_profile.index.isin(\n",
    "        profile_data_splits_df.loc[\n",
    "            profile_data_splits_df[\"data_split\"] == \"train_gt\"\n",
    "        ].index\n",
    "    )\n",
    "]\n",
    "val_gt_X = sc_profile.loc[\n",
    "    sc_profile.index.isin(\n",
    "        profile_data_splits_df.loc[\n",
    "            profile_data_splits_df[\"data_split\"] == \"val_gt\"\n",
    "        ].index\n",
    "    )\n",
    "]\n",
    "train_gt_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile.index.isin(\n",
    "        endpoint_data_splits_df.loc[\n",
    "            endpoint_data_splits_df[\"data_split\"] == \"train_gt\"\n",
    "        ].index\n",
    "    )\n",
    "]\n",
    "val_gt_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile.index.isin(\n",
    "        endpoint_data_splits_df.loc[\n",
    "            endpoint_data_splits_df[\"data_split\"] == \"val_gt\"\n",
    "        ].index\n",
    "    )\n",
    "]\n",
    "\n",
    "# assertion checks\n",
    "assert train_gt_X.shape[0] == train_gt_y.shape[0]\n",
    "assert val_gt_X.shape[0] == val_gt_y.shape[0]\n",
    "assert train_gt_X.shape[1] == val_gt_X.shape[1]\n",
    "assert train_gt_y.shape[1] == val_gt_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1345311/735914267.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
      "/tmp/ipykernel_1345311/735914267.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_gt_y.drop(columns=metadata_y_cols, inplace=True)\n",
      "/tmp/ipykernel_1345311/735914267.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
      "/tmp/ipykernel_1345311/735914267.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  val_gt_y.drop(columns=metadata_y_cols, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# get metadata\n",
    "metadata_X_cols = [x for x in train_gt_X.columns if \"Metadata_\" in x]\n",
    "metadata_y_cols = [x for x in train_gt_y.columns if \"Metadata_\" in x]\n",
    "\n",
    "\n",
    "train_gt_X_metadata = train_gt_X[metadata_X_cols]\n",
    "train_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
    "train_gt_y_metadata = train_gt_y[metadata_y_cols]\n",
    "train_gt_y.drop(columns=metadata_y_cols, inplace=True)\n",
    "val_gt_X_metadata = val_gt_X[metadata_X_cols]\n",
    "val_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
    "val_gt_y_metadata = val_gt_y[metadata_y_cols]\n",
    "val_gt_y.drop(columns=metadata_y_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "shuffled_train_gt_X = train_gt_X.copy()\n",
    "for col in shuffled_train_gt_X.columns:\n",
    "    if col.startswith(\"Metadata_\"):\n",
    "        continue\n",
    "    shuffled_train_gt_X[col] = np.random.permutation(shuffled_train_gt_X[col].values)\n",
    "shuffled_val_gt_X = val_gt_X.copy()\n",
    "for col in shuffled_val_gt_X.columns:\n",
    "    if col.startswith(\"Metadata_\"):\n",
    "        continue\n",
    "    shuffled_val_gt_X[col] = np.random.permutation(shuffled_val_gt_X[col].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 2338\n",
      "n_outputs: 1\n",
      "n_metadata_features: 38\n"
     ]
    }
   ],
   "source": [
    "# number of input features\n",
    "n_features = train_gt_X.shape[1]\n",
    "# number of output features\n",
    "n_outputs = train_gt_y.shape[1]\n",
    "# number of metadata features\n",
    "n_metadata_features = train_gt_X_metadata.shape[1]\n",
    "\n",
    "print(f\"n_features: {n_features}\")\n",
    "print(f\"n_outputs: {n_outputs}\")\n",
    "print(f\"n_metadata_features: {n_metadata_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "ml_configs = toml.load(\"../ML_utils/regression_class_config.toml\")\n",
    "mlp_params = parameter_set(params, ml_configs)\n",
    "mlp_params.IN_FEATURES = n_features\n",
    "mlp_params.OUT_FEATURES = n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 2338) (367, 1)\n",
      "(49, 2338) (49, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_gt_X.shape, train_gt_y.shape)\n",
    "print(val_gt_X.shape, val_gt_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(train_gt_X.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_gt_y.values, dtype=torch.float32)\n",
    "X_val = torch.tensor(val_gt_X.values, dtype=torch.float32)\n",
    "y_val = torch.tensor(val_gt_y.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtypes: torch.float32\n",
      "y_train dtypes: torch.float32\n",
      "X_val dtypes: torch.float32\n",
      "y_val dtypes: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# get the dtypes of the data\n",
    "print(f\"X_train dtypes: {X_train.dtype}\")\n",
    "print(f\"y_train dtypes: {y_train.dtype}\")\n",
    "print(f\"X_val dtypes: {X_val.dtype}\")\n",
    "print(f\"y_val dtypes: {y_val.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce data objects for train, val and test datasets\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_data = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "\n",
    "\n",
    "# convert data class into a dataloader to be compatible with pytorch\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data, batch_size=mlp_params.HYPERPARAMETER_BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_data, batch_size=mlp_params.HYPERPARAMETER_BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD\n",
      "Epoch 0: Validation loss decreased (inf --> 0.554434).  Saving model ...\n",
      "\t Train_Loss: 1.1243 Val_Loss: 0.5544  BEST VAL Loss: 0.5544 \n",
      "\n",
      "Epoch 1: Validation loss decreased (0.554434 --> 0.554351).  Saving model ...\n",
      "\t Train_Loss: 1.1234 Val_Loss: 0.5544  BEST VAL Loss: 0.5544 \n",
      "\n",
      "Epoch 2: Validation loss decreased (0.554351 --> 0.554269).  Saving model ...\n",
      "\t Train_Loss: 1.1230 Val_Loss: 0.5543  BEST VAL Loss: 0.5543 \n",
      "\n",
      "Epoch 3: Validation loss decreased (0.554269 --> 0.554187).  Saving model ...\n",
      "\t Train_Loss: 1.1228 Val_Loss: 0.5542  BEST VAL Loss: 0.5542 \n",
      "\n",
      "Epoch 4: Validation loss decreased (0.554187 --> 0.554107).  Saving model ...\n",
      "\t Train_Loss: 1.1227 Val_Loss: 0.5541  BEST VAL Loss: 0.5541 \n",
      "\n",
      "Epoch 5: Validation loss decreased (0.554107 --> 0.554028).  Saving model ...\n",
      "\t Train_Loss: 1.1227 Val_Loss: 0.5540  BEST VAL Loss: 0.5540 \n",
      "\n",
      "Epoch 6: Validation loss decreased (0.554028 --> 0.553950).  Saving model ...\n",
      "\t Train_Loss: 1.1225 Val_Loss: 0.5540  BEST VAL Loss: 0.5540 \n",
      "\n",
      "Epoch 7: Validation loss decreased (0.553950 --> 0.553873).  Saving model ...\n",
      "\t Train_Loss: 1.1224 Val_Loss: 0.5539  BEST VAL Loss: 0.5539 \n",
      "\n",
      "Epoch 8: Validation loss decreased (0.553873 --> 0.553797).  Saving model ...\n",
      "\t Train_Loss: 1.1222 Val_Loss: 0.5538  BEST VAL Loss: 0.5538 \n",
      "\n",
      "Epoch 9: Validation loss decreased (0.553797 --> 0.553722).  Saving model ...\n",
      "\t Train_Loss: 1.1220 Val_Loss: 0.5537  BEST VAL Loss: 0.5537 \n",
      "\n",
      "Epoch 10: Validation loss decreased (0.553722 --> 0.553648).  Saving model ...\n",
      "\t Train_Loss: 1.1217 Val_Loss: 0.5536  BEST VAL Loss: 0.5536 \n",
      "\n",
      "Epoch 11: Validation loss decreased (0.553648 --> 0.553575).  Saving model ...\n",
      "\t Train_Loss: 1.1215 Val_Loss: 0.5536  BEST VAL Loss: 0.5536 \n",
      "\n",
      "Epoch 12: Validation loss decreased (0.553575 --> 0.553502).  Saving model ...\n",
      "\t Train_Loss: 1.1213 Val_Loss: 0.5535  BEST VAL Loss: 0.5535 \n",
      "\n",
      "Epoch 13: Validation loss decreased (0.553502 --> 0.553431).  Saving model ...\n",
      "\t Train_Loss: 1.1212 Val_Loss: 0.5534  BEST VAL Loss: 0.5534 \n",
      "\n",
      "Epoch 14: Validation loss decreased (0.553431 --> 0.553360).  Saving model ...\n",
      "\t Train_Loss: 1.1210 Val_Loss: 0.5534  BEST VAL Loss: 0.5534 \n",
      "\n",
      "Epoch 15: Validation loss decreased (0.553360 --> 0.553290).  Saving model ...\n",
      "\t Train_Loss: 1.1209 Val_Loss: 0.5533  BEST VAL Loss: 0.5533 \n",
      "\n",
      "Epoch 16: Validation loss decreased (0.553290 --> 0.553221).  Saving model ...\n",
      "\t Train_Loss: 1.1207 Val_Loss: 0.5532  BEST VAL Loss: 0.5532 \n",
      "\n",
      "Epoch 17: Validation loss decreased (0.553221 --> 0.553153).  Saving model ...\n",
      "\t Train_Loss: 1.1205 Val_Loss: 0.5532  BEST VAL Loss: 0.5532 \n",
      "\n",
      "Epoch 18: Validation loss decreased (0.553153 --> 0.553086).  Saving model ...\n",
      "\t Train_Loss: 1.1204 Val_Loss: 0.5531  BEST VAL Loss: 0.5531 \n",
      "\n",
      "Epoch 19: Validation loss decreased (0.553086 --> 0.553019).  Saving model ...\n",
      "\t Train_Loss: 1.1202 Val_Loss: 0.5530  BEST VAL Loss: 0.5530 \n",
      "\n",
      "Epoch 20: Validation loss decreased (0.553019 --> 0.552953).  Saving model ...\n",
      "\t Train_Loss: 1.1201 Val_Loss: 0.5530  BEST VAL Loss: 0.5530 \n",
      "\n",
      "Epoch 21: Validation loss decreased (0.552953 --> 0.552888).  Saving model ...\n",
      "\t Train_Loss: 1.1199 Val_Loss: 0.5529  BEST VAL Loss: 0.5529 \n",
      "\n",
      "Epoch 22: Validation loss decreased (0.552888 --> 0.552824).  Saving model ...\n",
      "\t Train_Loss: 1.1198 Val_Loss: 0.5528  BEST VAL Loss: 0.5528 \n",
      "\n",
      "Epoch 23: Validation loss decreased (0.552824 --> 0.552761).  Saving model ...\n",
      "\t Train_Loss: 1.1196 Val_Loss: 0.5528  BEST VAL Loss: 0.5528 \n",
      "\n",
      "Epoch 24: Validation loss decreased (0.552761 --> 0.552698).  Saving model ...\n",
      "\t Train_Loss: 1.1194 Val_Loss: 0.5527  BEST VAL Loss: 0.5527 \n",
      "\n",
      "Epoch 25: Validation loss decreased (0.552698 --> 0.552636).  Saving model ...\n",
      "\t Train_Loss: 1.1192 Val_Loss: 0.5526  BEST VAL Loss: 0.5526 \n",
      "\n",
      "Epoch 26: Validation loss decreased (0.552636 --> 0.552575).  Saving model ...\n",
      "\t Train_Loss: 1.1191 Val_Loss: 0.5526  BEST VAL Loss: 0.5526 \n",
      "\n",
      "Epoch 27: Validation loss decreased (0.552575 --> 0.552514).  Saving model ...\n",
      "\t Train_Loss: 1.1189 Val_Loss: 0.5525  BEST VAL Loss: 0.5525 \n",
      "\n",
      "Epoch 28: Validation loss decreased (0.552514 --> 0.552455).  Saving model ...\n",
      "\t Train_Loss: 1.1188 Val_Loss: 0.5525  BEST VAL Loss: 0.5525 \n",
      "\n",
      "Epoch 29: Validation loss decreased (0.552455 --> 0.552396).  Saving model ...\n",
      "\t Train_Loss: 1.1186 Val_Loss: 0.5524  BEST VAL Loss: 0.5524 \n",
      "\n",
      "Epoch 30: Validation loss decreased (0.552396 --> 0.552338).  Saving model ...\n",
      "\t Train_Loss: 1.1185 Val_Loss: 0.5523  BEST VAL Loss: 0.5523 \n",
      "\n",
      "Epoch 31: Validation loss decreased (0.552338 --> 0.552280).  Saving model ...\n",
      "\t Train_Loss: 1.1183 Val_Loss: 0.5523  BEST VAL Loss: 0.5523 \n",
      "\n",
      "Epoch 32: Validation loss decreased (0.552280 --> 0.552223).  Saving model ...\n",
      "\t Train_Loss: 1.1182 Val_Loss: 0.5522  BEST VAL Loss: 0.5522 \n",
      "\n",
      "Epoch 33: Validation loss decreased (0.552223 --> 0.552167).  Saving model ...\n",
      "\t Train_Loss: 1.1181 Val_Loss: 0.5522  BEST VAL Loss: 0.5522 \n",
      "\n",
      "Epoch 34: Validation loss decreased (0.552167 --> 0.552112).  Saving model ...\n",
      "\t Train_Loss: 1.1179 Val_Loss: 0.5521  BEST VAL Loss: 0.5521 \n",
      "\n",
      "Epoch 35: Validation loss decreased (0.552112 --> 0.552057).  Saving model ...\n",
      "\t Train_Loss: 1.1177 Val_Loss: 0.5521  BEST VAL Loss: 0.5521 \n",
      "\n",
      "Epoch 36: Validation loss decreased (0.552057 --> 0.552003).  Saving model ...\n",
      "\t Train_Loss: 1.1176 Val_Loss: 0.5520  BEST VAL Loss: 0.5520 \n",
      "\n",
      "Epoch 37: Validation loss decreased (0.552003 --> 0.551950).  Saving model ...\n",
      "\t Train_Loss: 1.1174 Val_Loss: 0.5520  BEST VAL Loss: 0.5520 \n",
      "\n",
      "Epoch 38: Validation loss decreased (0.551950 --> 0.551898).  Saving model ...\n",
      "\t Train_Loss: 1.1173 Val_Loss: 0.5519  BEST VAL Loss: 0.5519 \n",
      "\n",
      "Epoch 39: Validation loss decreased (0.551898 --> 0.551846).  Saving model ...\n",
      "\t Train_Loss: 1.1171 Val_Loss: 0.5518  BEST VAL Loss: 0.5518 \n",
      "\n",
      "Epoch 40: Validation loss decreased (0.551846 --> 0.551795).  Saving model ...\n",
      "\t Train_Loss: 1.1170 Val_Loss: 0.5518  BEST VAL Loss: 0.5518 \n",
      "\n",
      "Epoch 41: Validation loss decreased (0.551795 --> 0.551744).  Saving model ...\n",
      "\t Train_Loss: 1.1168 Val_Loss: 0.5517  BEST VAL Loss: 0.5517 \n",
      "\n",
      "Epoch 42: Validation loss decreased (0.551744 --> 0.551694).  Saving model ...\n",
      "\t Train_Loss: 1.1167 Val_Loss: 0.5517  BEST VAL Loss: 0.5517 \n",
      "\n",
      "Epoch 43: Validation loss decreased (0.551694 --> 0.551645).  Saving model ...\n",
      "\t Train_Loss: 1.1165 Val_Loss: 0.5516  BEST VAL Loss: 0.5516 \n",
      "\n",
      "Epoch 44: Validation loss decreased (0.551645 --> 0.551597).  Saving model ...\n",
      "\t Train_Loss: 1.1164 Val_Loss: 0.5516  BEST VAL Loss: 0.5516 \n",
      "\n",
      "Epoch 45: Validation loss decreased (0.551597 --> 0.551549).  Saving model ...\n",
      "\t Train_Loss: 1.1162 Val_Loss: 0.5515  BEST VAL Loss: 0.5515 \n",
      "\n",
      "Epoch 46: Validation loss decreased (0.551549 --> 0.551502).  Saving model ...\n",
      "\t Train_Loss: 1.1161 Val_Loss: 0.5515  BEST VAL Loss: 0.5515 \n",
      "\n",
      "Epoch 47: Validation loss decreased (0.551502 --> 0.551455).  Saving model ...\n",
      "\t Train_Loss: 1.1160 Val_Loss: 0.5515  BEST VAL Loss: 0.5515 \n",
      "\n",
      "Epoch 48: Validation loss decreased (0.551455 --> 0.551410).  Saving model ...\n",
      "\t Train_Loss: 1.1158 Val_Loss: 0.5514  BEST VAL Loss: 0.5514 \n",
      "\n",
      "Epoch 49: Validation loss decreased (0.551410 --> 0.551364).  Saving model ...\n",
      "\t Train_Loss: 1.1157 Val_Loss: 0.5514  BEST VAL Loss: 0.5514 \n",
      "\n",
      "Epoch 50: Validation loss decreased (0.551364 --> 0.551320).  Saving model ...\n",
      "\t Train_Loss: 1.1156 Val_Loss: 0.5513  BEST VAL Loss: 0.5513 \n",
      "\n",
      "Epoch 51: Validation loss decreased (0.551320 --> 0.551276).  Saving model ...\n",
      "\t Train_Loss: 1.1154 Val_Loss: 0.5513  BEST VAL Loss: 0.5513 \n",
      "\n",
      "Epoch 52: Validation loss decreased (0.551276 --> 0.551233).  Saving model ...\n",
      "\t Train_Loss: 1.1153 Val_Loss: 0.5512  BEST VAL Loss: 0.5512 \n",
      "\n",
      "Epoch 53: Validation loss decreased (0.551233 --> 0.551190).  Saving model ...\n",
      "\t Train_Loss: 1.1152 Val_Loss: 0.5512  BEST VAL Loss: 0.5512 \n",
      "\n",
      "Epoch 54: Validation loss decreased (0.551190 --> 0.551148).  Saving model ...\n",
      "\t Train_Loss: 1.1150 Val_Loss: 0.5511  BEST VAL Loss: 0.5511 \n",
      "\n",
      "Epoch 55: Validation loss decreased (0.551148 --> 0.551106).  Saving model ...\n",
      "\t Train_Loss: 1.1149 Val_Loss: 0.5511  BEST VAL Loss: 0.5511 \n",
      "\n",
      "Epoch 56: Validation loss decreased (0.551106 --> 0.551065).  Saving model ...\n",
      "\t Train_Loss: 1.1148 Val_Loss: 0.5511  BEST VAL Loss: 0.5511 \n",
      "\n",
      "Epoch 57: Validation loss decreased (0.551065 --> 0.551025).  Saving model ...\n",
      "\t Train_Loss: 1.1146 Val_Loss: 0.5510  BEST VAL Loss: 0.5510 \n",
      "\n",
      "Epoch 58: Validation loss decreased (0.551025 --> 0.550985).  Saving model ...\n",
      "\t Train_Loss: 1.1145 Val_Loss: 0.5510  BEST VAL Loss: 0.5510 \n",
      "\n",
      "Epoch 59: Validation loss decreased (0.550985 --> 0.550945).  Saving model ...\n",
      "\t Train_Loss: 1.1144 Val_Loss: 0.5509  BEST VAL Loss: 0.5509 \n",
      "\n",
      "Epoch 60: Validation loss decreased (0.550945 --> 0.550907).  Saving model ...\n",
      "\t Train_Loss: 1.1142 Val_Loss: 0.5509  BEST VAL Loss: 0.5509 \n",
      "\n",
      "Epoch 61: Validation loss decreased (0.550907 --> 0.550868).  Saving model ...\n",
      "\t Train_Loss: 1.1141 Val_Loss: 0.5509  BEST VAL Loss: 0.5509 \n",
      "\n",
      "Epoch 62: Validation loss decreased (0.550868 --> 0.550831).  Saving model ...\n",
      "\t Train_Loss: 1.1140 Val_Loss: 0.5508  BEST VAL Loss: 0.5508 \n",
      "\n",
      "Epoch 63: Validation loss decreased (0.550831 --> 0.550793).  Saving model ...\n",
      "\t Train_Loss: 1.1138 Val_Loss: 0.5508  BEST VAL Loss: 0.5508 \n",
      "\n",
      "Epoch 64: Validation loss decreased (0.550793 --> 0.550757).  Saving model ...\n",
      "\t Train_Loss: 1.1137 Val_Loss: 0.5508  BEST VAL Loss: 0.5508 \n",
      "\n",
      "Epoch 65: Validation loss decreased (0.550757 --> 0.550721).  Saving model ...\n",
      "\t Train_Loss: 1.1136 Val_Loss: 0.5507  BEST VAL Loss: 0.5507 \n",
      "\n",
      "Epoch 66: Validation loss decreased (0.550721 --> 0.550685).  Saving model ...\n",
      "\t Train_Loss: 1.1134 Val_Loss: 0.5507  BEST VAL Loss: 0.5507 \n",
      "\n",
      "Epoch 67: Validation loss decreased (0.550685 --> 0.550650).  Saving model ...\n",
      "\t Train_Loss: 1.1133 Val_Loss: 0.5506  BEST VAL Loss: 0.5506 \n",
      "\n",
      "Epoch 68: Validation loss decreased (0.550650 --> 0.550615).  Saving model ...\n",
      "\t Train_Loss: 1.1132 Val_Loss: 0.5506  BEST VAL Loss: 0.5506 \n",
      "\n",
      "Epoch 69: Validation loss decreased (0.550615 --> 0.550581).  Saving model ...\n",
      "\t Train_Loss: 1.1131 Val_Loss: 0.5506  BEST VAL Loss: 0.5506 \n",
      "\n",
      "Epoch 70: Validation loss decreased (0.550581 --> 0.550547).  Saving model ...\n",
      "\t Train_Loss: 1.1130 Val_Loss: 0.5505  BEST VAL Loss: 0.5505 \n",
      "\n",
      "Epoch 71: Validation loss decreased (0.550547 --> 0.550514).  Saving model ...\n",
      "\t Train_Loss: 1.1128 Val_Loss: 0.5505  BEST VAL Loss: 0.5505 \n",
      "\n",
      "Epoch 72: Validation loss decreased (0.550514 --> 0.550481).  Saving model ...\n",
      "\t Train_Loss: 1.1127 Val_Loss: 0.5505  BEST VAL Loss: 0.5505 \n",
      "\n",
      "Epoch 73: Validation loss decreased (0.550481 --> 0.550449).  Saving model ...\n",
      "\t Train_Loss: 1.1126 Val_Loss: 0.5504  BEST VAL Loss: 0.5504 \n",
      "\n",
      "Epoch 74: Validation loss decreased (0.550449 --> 0.550417).  Saving model ...\n",
      "\t Train_Loss: 1.1125 Val_Loss: 0.5504  BEST VAL Loss: 0.5504 \n",
      "\n",
      "Epoch 75: Validation loss decreased (0.550417 --> 0.550386).  Saving model ...\n",
      "\t Train_Loss: 1.1124 Val_Loss: 0.5504  BEST VAL Loss: 0.5504 \n",
      "\n",
      "Epoch 76: Validation loss decreased (0.550386 --> 0.550355).  Saving model ...\n",
      "\t Train_Loss: 1.1123 Val_Loss: 0.5504  BEST VAL Loss: 0.5504 \n",
      "\n",
      "Epoch 77: Validation loss decreased (0.550355 --> 0.550325).  Saving model ...\n",
      "\t Train_Loss: 1.1122 Val_Loss: 0.5503  BEST VAL Loss: 0.5503 \n",
      "\n",
      "Epoch 78: Validation loss decreased (0.550325 --> 0.550295).  Saving model ...\n",
      "\t Train_Loss: 1.1120 Val_Loss: 0.5503  BEST VAL Loss: 0.5503 \n",
      "\n",
      "Epoch 79: Validation loss decreased (0.550295 --> 0.550266).  Saving model ...\n",
      "\t Train_Loss: 1.1119 Val_Loss: 0.5503  BEST VAL Loss: 0.5503 \n",
      "\n",
      "Epoch 80: Validation loss decreased (0.550266 --> 0.550237).  Saving model ...\n",
      "\t Train_Loss: 1.1118 Val_Loss: 0.5502  BEST VAL Loss: 0.5502 \n",
      "\n",
      "Epoch 81: Validation loss decreased (0.550237 --> 0.550208).  Saving model ...\n",
      "\t Train_Loss: 1.1117 Val_Loss: 0.5502  BEST VAL Loss: 0.5502 \n",
      "\n",
      "Epoch 82: Validation loss decreased (0.550208 --> 0.550180).  Saving model ...\n",
      "\t Train_Loss: 1.1116 Val_Loss: 0.5502  BEST VAL Loss: 0.5502 \n",
      "\n",
      "Epoch 83: Validation loss decreased (0.550180 --> 0.550152).  Saving model ...\n",
      "\t Train_Loss: 1.1115 Val_Loss: 0.5502  BEST VAL Loss: 0.5502 \n",
      "\n",
      "Epoch 84: Validation loss decreased (0.550152 --> 0.550125).  Saving model ...\n",
      "\t Train_Loss: 1.1114 Val_Loss: 0.5501  BEST VAL Loss: 0.5501 \n",
      "\n",
      "Epoch 85: Validation loss decreased (0.550125 --> 0.550098).  Saving model ...\n",
      "\t Train_Loss: 1.1113 Val_Loss: 0.5501  BEST VAL Loss: 0.5501 \n",
      "\n",
      "Epoch 86: Validation loss decreased (0.550098 --> 0.550072).  Saving model ...\n",
      "\t Train_Loss: 1.1112 Val_Loss: 0.5501  BEST VAL Loss: 0.5501 \n",
      "\n",
      "Epoch 87: Validation loss decreased (0.550072 --> 0.550045).  Saving model ...\n",
      "\t Train_Loss: 1.1111 Val_Loss: 0.5500  BEST VAL Loss: 0.5500 \n",
      "\n",
      "Epoch 88: Validation loss decreased (0.550045 --> 0.550020).  Saving model ...\n",
      "\t Train_Loss: 1.1110 Val_Loss: 0.5500  BEST VAL Loss: 0.5500 \n",
      "\n",
      "Epoch 89: Validation loss decreased (0.550020 --> 0.549995).  Saving model ...\n",
      "\t Train_Loss: 1.1109 Val_Loss: 0.5500  BEST VAL Loss: 0.5500 \n",
      "\n",
      "Epoch 90: Validation loss decreased (0.549995 --> 0.549970).  Saving model ...\n",
      "\t Train_Loss: 1.1107 Val_Loss: 0.5500  BEST VAL Loss: 0.5500 \n",
      "\n",
      "Epoch 91: Validation loss decreased (0.549970 --> 0.549945).  Saving model ...\n",
      "\t Train_Loss: 1.1106 Val_Loss: 0.5499  BEST VAL Loss: 0.5499 \n",
      "\n",
      "Epoch 92: Validation loss decreased (0.549945 --> 0.549921).  Saving model ...\n",
      "\t Train_Loss: 1.1106 Val_Loss: 0.5499  BEST VAL Loss: 0.5499 \n",
      "\n",
      "Epoch 93: Validation loss decreased (0.549921 --> 0.549897).  Saving model ...\n",
      "\t Train_Loss: 1.1105 Val_Loss: 0.5499  BEST VAL Loss: 0.5499 \n",
      "\n",
      "Epoch 94: Validation loss decreased (0.549897 --> 0.549874).  Saving model ...\n",
      "\t Train_Loss: 1.1104 Val_Loss: 0.5499  BEST VAL Loss: 0.5499 \n",
      "\n",
      "Epoch 95: Validation loss decreased (0.549874 --> 0.549851).  Saving model ...\n",
      "\t Train_Loss: 1.1103 Val_Loss: 0.5499  BEST VAL Loss: 0.5499 \n",
      "\n",
      "Epoch 96: Validation loss decreased (0.549851 --> 0.549829).  Saving model ...\n",
      "\t Train_Loss: 1.1102 Val_Loss: 0.5498  BEST VAL Loss: 0.5498 \n",
      "\n",
      "Epoch 97: Validation loss decreased (0.549829 --> 0.549806).  Saving model ...\n",
      "\t Train_Loss: 1.1101 Val_Loss: 0.5498  BEST VAL Loss: 0.5498 \n",
      "\n",
      "Epoch 98: Validation loss decreased (0.549806 --> 0.549785).  Saving model ...\n",
      "\t Train_Loss: 1.1100 Val_Loss: 0.5498  BEST VAL Loss: 0.5498 \n",
      "\n",
      "Epoch 99: Validation loss decreased (0.549785 --> 0.549763).  Saving model ...\n",
      "\t Train_Loss: 1.1099 Val_Loss: 0.5498  BEST VAL Loss: 0.5498 \n",
      "\n",
      "Epoch 100: Validation loss decreased (0.549763 --> 0.549742).  Saving model ...\n",
      "\t Train_Loss: 1.1098 Val_Loss: 0.5497  BEST VAL Loss: 0.5497 \n",
      "\n",
      "Epoch 101: Validation loss decreased (0.549742 --> 0.549721).  Saving model ...\n",
      "\t Train_Loss: 1.1097 Val_Loss: 0.5497  BEST VAL Loss: 0.5497 \n",
      "\n",
      "Epoch 102: Validation loss decreased (0.549721 --> 0.549701).  Saving model ...\n",
      "\t Train_Loss: 1.1096 Val_Loss: 0.5497  BEST VAL Loss: 0.5497 \n",
      "\n",
      "Epoch 103: Validation loss decreased (0.549701 --> 0.549681).  Saving model ...\n",
      "\t Train_Loss: 1.1095 Val_Loss: 0.5497  BEST VAL Loss: 0.5497 \n",
      "\n",
      "Epoch 104: Validation loss decreased (0.549681 --> 0.549661).  Saving model ...\n",
      "\t Train_Loss: 1.1094 Val_Loss: 0.5497  BEST VAL Loss: 0.5497 \n",
      "\n",
      "Epoch 105: Validation loss decreased (0.549661 --> 0.549642).  Saving model ...\n",
      "\t Train_Loss: 1.1093 Val_Loss: 0.5496  BEST VAL Loss: 0.5496 \n",
      "\n",
      "Epoch 106: Validation loss decreased (0.549642 --> 0.549623).  Saving model ...\n",
      "\t Train_Loss: 1.1092 Val_Loss: 0.5496  BEST VAL Loss: 0.5496 \n",
      "\n",
      "Epoch 107: Validation loss decreased (0.549623 --> 0.549604).  Saving model ...\n",
      "\t Train_Loss: 1.1091 Val_Loss: 0.5496  BEST VAL Loss: 0.5496 \n",
      "\n",
      "Epoch 108: Validation loss decreased (0.549604 --> 0.549586).  Saving model ...\n",
      "\t Train_Loss: 1.1090 Val_Loss: 0.5496  BEST VAL Loss: 0.5496 \n",
      "\n",
      "Epoch 109: Validation loss decreased (0.549586 --> 0.549568).  Saving model ...\n",
      "\t Train_Loss: 1.1090 Val_Loss: 0.5496  BEST VAL Loss: 0.5496 \n",
      "\n",
      "Epoch 110: Validation loss decreased (0.549568 --> 0.549550).  Saving model ...\n",
      "\t Train_Loss: 1.1089 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 111: Validation loss decreased (0.549550 --> 0.549532).  Saving model ...\n",
      "\t Train_Loss: 1.1088 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 112: Validation loss decreased (0.549532 --> 0.549515).  Saving model ...\n",
      "\t Train_Loss: 1.1087 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 113: Validation loss decreased (0.549515 --> 0.549499).  Saving model ...\n",
      "\t Train_Loss: 1.1086 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 114: Validation loss decreased (0.549499 --> 0.549482).  Saving model ...\n",
      "\t Train_Loss: 1.1085 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 115: Validation loss decreased (0.549482 --> 0.549466).  Saving model ...\n",
      "\t Train_Loss: 1.1084 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 116: Validation loss decreased (0.549466 --> 0.549450).  Saving model ...\n",
      "\t Train_Loss: 1.1083 Val_Loss: 0.5495  BEST VAL Loss: 0.5495 \n",
      "\n",
      "Epoch 117: Validation loss decreased (0.549450 --> 0.549434).  Saving model ...\n",
      "\t Train_Loss: 1.1083 Val_Loss: 0.5494  BEST VAL Loss: 0.5494 \n",
      "\n",
      "Epoch 118: Validation loss decreased (0.549434 --> 0.549419).  Saving model ...\n",
      "\t Train_Loss: 1.1082 Val_Loss: 0.5494  BEST VAL Loss: 0.5494 \n",
      "\n",
      "Epoch 119: Validation loss decreased (0.549419 --> 0.549404).  Saving model ...\n",
      "\t Train_Loss: 1.1081 Val_Loss: 0.5494  BEST VAL Loss: 0.5494 \n",
      "\n",
      "Epoch 120: Validation loss decreased (0.549404 --> 0.549390).  Saving model ...\n",
      "\t Train_Loss: 1.1080 Val_Loss: 0.5494  BEST VAL Loss: 0.5494 \n",
      "\n",
      "Epoch 121: Validation loss decreased (0.549390 --> 0.549375).  Saving model ...\n",
      "\t Train_Loss: 1.1079 Val_Loss: 0.5494  BEST VAL Loss: 0.5494 \n",
      "\n",
      "Epoch 122: Validation loss decreased (0.549375 --> 0.549361).  Saving model ...\n",
      "\t Train_Loss: 1.1078 Val_Loss: 0.5494  BEST VAL Loss: 0.5494 \n",
      "\n",
      "Epoch 123: Validation loss decreased (0.549361 --> 0.549347).  Saving model ...\n",
      "\t Train_Loss: 1.1078 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 124: Validation loss decreased (0.549347 --> 0.549334).  Saving model ...\n",
      "\t Train_Loss: 1.1077 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 125: Validation loss decreased (0.549334 --> 0.549320).  Saving model ...\n",
      "\t Train_Loss: 1.1076 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 126: Validation loss decreased (0.549320 --> 0.549307).  Saving model ...\n",
      "\t Train_Loss: 1.1075 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 127: Validation loss decreased (0.549307 --> 0.549294).  Saving model ...\n",
      "\t Train_Loss: 1.1074 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 128: Validation loss decreased (0.549294 --> 0.549282).  Saving model ...\n",
      "\t Train_Loss: 1.1073 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 129: Validation loss decreased (0.549282 --> 0.549270).  Saving model ...\n",
      "\t Train_Loss: 1.1073 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 130: Validation loss decreased (0.549270 --> 0.549258).  Saving model ...\n",
      "\t Train_Loss: 1.1072 Val_Loss: 0.5493  BEST VAL Loss: 0.5493 \n",
      "\n",
      "Epoch 131: Validation loss decreased (0.549258 --> 0.549246).  Saving model ...\n",
      "\t Train_Loss: 1.1071 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 132: Validation loss decreased (0.549246 --> 0.549235).  Saving model ...\n",
      "\t Train_Loss: 1.1070 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 133: Validation loss decreased (0.549235 --> 0.549223).  Saving model ...\n",
      "\t Train_Loss: 1.1070 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 134: Validation loss decreased (0.549223 --> 0.549212).  Saving model ...\n",
      "\t Train_Loss: 1.1069 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 135: Validation loss decreased (0.549212 --> 0.549202).  Saving model ...\n",
      "\t Train_Loss: 1.1068 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 136: Validation loss decreased (0.549202 --> 0.549191).  Saving model ...\n",
      "\t Train_Loss: 1.1067 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 137: Validation loss decreased (0.549191 --> 0.549181).  Saving model ...\n",
      "\t Train_Loss: 1.1067 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 138: Validation loss decreased (0.549181 --> 0.549171).  Saving model ...\n",
      "\t Train_Loss: 1.1066 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 139: Validation loss decreased (0.549171 --> 0.549161).  Saving model ...\n",
      "\t Train_Loss: 1.1065 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 140: Validation loss decreased (0.549161 --> 0.549152).  Saving model ...\n",
      "\t Train_Loss: 1.1064 Val_Loss: 0.5492  BEST VAL Loss: 0.5492 \n",
      "\n",
      "Epoch 141: Validation loss decreased (0.549152 --> 0.549143).  Saving model ...\n",
      "\t Train_Loss: 1.1064 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 142: Validation loss decreased (0.549143 --> 0.549133).  Saving model ...\n",
      "\t Train_Loss: 1.1063 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 143: Validation loss decreased (0.549133 --> 0.549125).  Saving model ...\n",
      "\t Train_Loss: 1.1062 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 144: Validation loss decreased (0.549125 --> 0.549116).  Saving model ...\n",
      "\t Train_Loss: 1.1061 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 145: Validation loss decreased (0.549116 --> 0.549108).  Saving model ...\n",
      "\t Train_Loss: 1.1061 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 146: Validation loss decreased (0.549108 --> 0.549099).  Saving model ...\n",
      "\t Train_Loss: 1.1060 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 147: Validation loss decreased (0.549099 --> 0.549092).  Saving model ...\n",
      "\t Train_Loss: 1.1059 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 148: Validation loss decreased (0.549092 --> 0.549084).  Saving model ...\n",
      "\t Train_Loss: 1.1059 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 149: Validation loss decreased (0.549084 --> 0.549076).  Saving model ...\n",
      "\t Train_Loss: 1.1058 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 150: Validation loss decreased (0.549076 --> 0.549069).  Saving model ...\n",
      "\t Train_Loss: 1.1057 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 151: Validation loss decreased (0.549069 --> 0.549062).  Saving model ...\n",
      "\t Train_Loss: 1.1056 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 152: Validation loss decreased (0.549062 --> 0.549055).  Saving model ...\n",
      "\t Train_Loss: 1.1056 Val_Loss: 0.5491  BEST VAL Loss: 0.5491 \n",
      "\n",
      "Epoch 153: Validation loss decreased (0.549055 --> 0.549048).  Saving model ...\n",
      "\t Train_Loss: 1.1055 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 154: Validation loss decreased (0.549048 --> 0.549042).  Saving model ...\n",
      "\t Train_Loss: 1.1054 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 155: Validation loss decreased (0.549042 --> 0.549035).  Saving model ...\n",
      "\t Train_Loss: 1.1054 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 156: Validation loss decreased (0.549035 --> 0.549029).  Saving model ...\n",
      "\t Train_Loss: 1.1053 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 157: Validation loss decreased (0.549029 --> 0.549023).  Saving model ...\n",
      "\t Train_Loss: 1.1052 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 158: Validation loss decreased (0.549023 --> 0.549018).  Saving model ...\n",
      "\t Train_Loss: 1.1052 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 159: Validation loss decreased (0.549018 --> 0.549012).  Saving model ...\n",
      "\t Train_Loss: 1.1051 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 160: Validation loss decreased (0.549012 --> 0.549007).  Saving model ...\n",
      "\t Train_Loss: 1.1050 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 161: Validation loss decreased (0.549007 --> 0.549002).  Saving model ...\n",
      "\t Train_Loss: 1.1050 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 162: Validation loss decreased (0.549002 --> 0.548997).  Saving model ...\n",
      "\t Train_Loss: 1.1049 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 163: Validation loss decreased (0.548997 --> 0.548992).  Saving model ...\n",
      "\t Train_Loss: 1.1048 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 164: Validation loss decreased (0.548992 --> 0.548987).  Saving model ...\n",
      "\t Train_Loss: 1.1048 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 165: Validation loss decreased (0.548987 --> 0.548983).  Saving model ...\n",
      "\t Train_Loss: 1.1047 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 166: Validation loss decreased (0.548983 --> 0.548979).  Saving model ...\n",
      "\t Train_Loss: 1.1047 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 167: Validation loss decreased (0.548979 --> 0.548975).  Saving model ...\n",
      "\t Train_Loss: 1.1046 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 168: Validation loss decreased (0.548975 --> 0.548971).  Saving model ...\n",
      "\t Train_Loss: 1.1045 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 169: Validation loss decreased (0.548971 --> 0.548967).  Saving model ...\n",
      "\t Train_Loss: 1.1045 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 170: Validation loss decreased (0.548967 --> 0.548963).  Saving model ...\n",
      "\t Train_Loss: 1.1044 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 171: Validation loss decreased (0.548963 --> 0.548960).  Saving model ...\n",
      "\t Train_Loss: 1.1043 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 172: Validation loss decreased (0.548960 --> 0.548957).  Saving model ...\n",
      "\t Train_Loss: 1.1043 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 173: Validation loss decreased (0.548957 --> 0.548954).  Saving model ...\n",
      "\t Train_Loss: 1.1042 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 174: Validation loss decreased (0.548954 --> 0.548951).  Saving model ...\n",
      "\t Train_Loss: 1.1042 Val_Loss: 0.5490  BEST VAL Loss: 0.5490 \n",
      "\n",
      "Epoch 175: Validation loss decreased (0.548951 --> 0.548948).  Saving model ...\n",
      "\t Train_Loss: 1.1041 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 176: Validation loss decreased (0.548948 --> 0.548946).  Saving model ...\n",
      "\t Train_Loss: 1.1040 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 177: Validation loss decreased (0.548946 --> 0.548943).  Saving model ...\n",
      "\t Train_Loss: 1.1040 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 178: Validation loss decreased (0.548943 --> 0.548941).  Saving model ...\n",
      "\t Train_Loss: 1.1039 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 179: Validation loss decreased (0.548941 --> 0.548939).  Saving model ...\n",
      "\t Train_Loss: 1.1039 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 180: Validation loss decreased (0.548939 --> 0.548937).  Saving model ...\n",
      "\t Train_Loss: 1.1038 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 181: Validation loss decreased (0.548937 --> 0.548935).  Saving model ...\n",
      "\t Train_Loss: 1.1037 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 182: Validation loss decreased (0.548935 --> 0.548933).  Saving model ...\n",
      "\t Train_Loss: 1.1037 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 183: Validation loss decreased (0.548933 --> 0.548932).  Saving model ...\n",
      "\t Train_Loss: 1.1036 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 184: Validation loss decreased (0.548932 --> 0.548931).  Saving model ...\n",
      "\t Train_Loss: 1.1036 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 185: Validation loss decreased (0.548931 --> 0.548929).  Saving model ...\n",
      "\t Train_Loss: 1.1035 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 186: Validation loss decreased (0.548929 --> 0.548928).  Saving model ...\n",
      "\t Train_Loss: 1.1035 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 187: Validation loss decreased (0.548928 --> 0.548927).  Saving model ...\n",
      "\t Train_Loss: 1.1034 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 188: Validation loss decreased (0.548927 --> 0.548927).  Saving model ...\n",
      "\t Train_Loss: 1.1033 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 189: Validation loss decreased (0.548927 --> 0.548926).  Saving model ...\n",
      "\t Train_Loss: 1.1033 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 190: Validation loss decreased (0.548926 --> 0.548926).  Saving model ...\n",
      "\t Train_Loss: 1.1032 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 191: Validation loss decreased (0.548926 --> 0.548925).  Saving model ...\n",
      "\t Train_Loss: 1.1032 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 192: Validation loss decreased (0.548925 --> 0.548925).  Saving model ...\n",
      "\t Train_Loss: 1.1031 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 193: Validation loss decreased (0.548925 --> 0.548925).  Saving model ...\n",
      "\t Train_Loss: 1.1031 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 194: Validation loss did not decrease\n",
      "\t Train_Loss: 1.1030 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 195: Validation loss did not decrease\n",
      "\t Train_Loss: 1.1030 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 196: Validation loss did not decrease\n",
      "\t Train_Loss: 1.1029 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 197: Validation loss did not decrease\n",
      "\t Train_Loss: 1.1028 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 198: Validation loss did not decrease\n",
      "\t Train_Loss: 1.1028 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n",
      "Epoch 199: Validation loss did not decrease\n",
      "\t Train_Loss: 1.1027 Val_Loss: 0.5489  BEST VAL Loss: 0.5489 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# call the optimized training model\n",
    "(\n",
    "    train_loss,\n",
    "    valid_loss,\n",
    "    epochs_ran,\n",
    "    model,\n",
    ") = train_optimized_model(\n",
    "    EPOCHS=mlp_params.TRAIN_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=valid_loader,\n",
    "    params=mlp_params,\n",
    "    model_name=\"Cells_Intensity_MeanIntensityEdge_AnnexinV\",\n",
    "    shuffle=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
