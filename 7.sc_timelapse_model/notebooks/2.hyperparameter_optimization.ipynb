{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pathlib\n",
    "import pprint\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import toml\n",
    "import torch\n",
    "from optuna.samplers import RandomSampler\n",
    "\n",
    "sys.path.append(\"../ML_utils/\")\n",
    "\n",
    "from create_optimized_model import optimized_model_create\n",
    "from extract_best_trial import extract_best_trial_params\n",
    "from objective_creation import objective_model_optimizer\n",
    "from parameter_set import parameter_set\n",
    "from parameters import Parameters\n",
    "\n",
    "try:\n",
    "    cfg = get_ipython().config\n",
    "    in_notebook = True\n",
    "except NameError:\n",
    "    in_notebook = False\n",
    "if in_notebook:\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_profile shape: (182804, 2376)\n",
      "sc_endpoint_profile shape: (11340, 368)\n",
      "data_split_df shape: (182804, 3)\n"
     ]
    }
   ],
   "source": [
    "# read in the data\n",
    "sc_file_path = pathlib.Path(\"../results/cleaned_sc_profile.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "sc_endpoint_file_path = pathlib.Path(\n",
    "    \"../results/cleaned_endpoint_sc_profile.parquet\"\n",
    ").resolve(strict=True)\n",
    "\n",
    "data_split_file_path = pathlib.Path(\"../results/data_splits.parquet\").resolve(\n",
    "    strict=True\n",
    ")\n",
    "\n",
    "sc_profile = pd.read_parquet(sc_file_path)\n",
    "sc_endpoint_profile = pd.read_parquet(sc_endpoint_file_path)\n",
    "data_split_df = pd.read_parquet(data_split_file_path)\n",
    "print(f\"sc_profile shape: {sc_profile.shape}\")\n",
    "print(f\"sc_endpoint_profile shape: {sc_endpoint_profile.shape}\")\n",
    "print(f\"data_split_df shape: {data_split_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the sc_profile and data_split_df\n",
    "sc_profile = pd.concat(\n",
    "    [\n",
    "        sc_profile,\n",
    "        data_split_df[[\"ground_truth\", \"data_split\"]],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "sc_profile.rename(\n",
    "    columns={\n",
    "        \"ground_truth\": \"Metadata_ground_truth\",\n",
    "        \"data_split\": \"Metadata_data_split\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sc_profile shape after dropping NaN: (14237, 2378)\n",
      "sc_endpoint_profile shape after dropping NaN: (11136, 368)\n"
     ]
    }
   ],
   "source": [
    "# keep only the last timepoint\n",
    "sc_profile[\"Metadata_Time\"] = sc_profile[\"Metadata_Time\"].astype(\"float64\")\n",
    "sc_profile = sc_profile[\n",
    "    sc_profile[\"Metadata_Time\"] == sc_profile[\"Metadata_Time\"].max()\n",
    "]\n",
    "# drop Na values\n",
    "sc_profile.dropna(inplace=True)\n",
    "print(f\"sc_profile shape after dropping NaN: {sc_profile.shape}\")\n",
    "sc_endpoint_profile.dropna(inplace=True)\n",
    "print(f\"sc_endpoint_profile shape after dropping NaN: {sc_endpoint_profile.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hardcode the features that should exist in the y data\n",
    "# this will be replaced in the future by an arg or config passed through\n",
    "selected_y_features = [\"Cells_Intensity_MeanIntensityEdge_AnnexinV\"]\n",
    "metadata_y_features = [x for x in sc_endpoint_profile.columns if \"Metadata_\" in x]\n",
    "sc_endpoint_profile = sc_endpoint_profile[metadata_y_features + selected_y_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_gt_X shape: (372, 2378)\n",
      "val_gt_X shape: (50, 2378)\n",
      "test_gt_X shape: (49, 2378)\n",
      "test_wo_gt_X shape: (9137, 2378)\n",
      "holdout_w_gt_X shape: (244, 2378)\n",
      "holdout_wo_gt_X shape: (4385, 2378)\n"
     ]
    }
   ],
   "source": [
    "train_gt_X = sc_profile.loc[\n",
    "    (sc_profile[\"Metadata_data_split\"] == \"train\")\n",
    "    & (sc_profile[\"Metadata_ground_truth\"] == True)\n",
    "]\n",
    "val_gt_X = sc_profile.loc[\n",
    "    (sc_profile[\"Metadata_data_split\"] == \"val\")\n",
    "    & (sc_profile[\"Metadata_ground_truth\"] == True)\n",
    "]\n",
    "test_gt_X = sc_profile.loc[\n",
    "    (sc_profile[\"Metadata_data_split\"] == \"test\")\n",
    "    & (sc_profile[\"Metadata_ground_truth\"] == True)\n",
    "]\n",
    "test_wo_gt_X = sc_profile.loc[\n",
    "    (sc_profile[\"Metadata_data_split\"] == \"test\")\n",
    "    & (sc_profile[\"Metadata_ground_truth\"] == False)\n",
    "]\n",
    "holdout_w_gt_X = sc_profile.loc[\n",
    "    (sc_profile[\"Metadata_data_split\"] == \"well_holdout\")\n",
    "    & (sc_profile[\"Metadata_ground_truth\"] == True)\n",
    "]\n",
    "holdout_wo_gt_X = sc_profile.loc[\n",
    "    (sc_profile[\"Metadata_data_split\"] == \"well_holdout\")\n",
    "    & (sc_profile[\"Metadata_ground_truth\"] == False)\n",
    "]\n",
    "print(f\"train_gt_X shape: {train_gt_X.shape}\")\n",
    "print(f\"val_gt_X shape: {val_gt_X.shape}\")\n",
    "print(f\"test_gt_X shape: {test_gt_X.shape}\")\n",
    "print(f\"test_wo_gt_X shape: {test_wo_gt_X.shape}\")\n",
    "print(f\"holdout_w_gt_X shape: {holdout_w_gt_X.shape}\")\n",
    "print(f\"holdout_wo_gt_X shape: {holdout_wo_gt_X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df_x_Metadata_sc_unique_track_id shape: (372,)\n",
      "val_df_x_Metadata_sc_unique_track_id shape: (50,)\n",
      "test_df_x_Metadata_sc_unique_track_id shape: (49,)\n",
      "holdout_w_df_x_Metadata_sc_unique_track_id shape: (244,)\n"
     ]
    }
   ],
   "source": [
    "# now let us get the the Metadata_sc_unique_track_id for each of the data splits with gt\n",
    "train_df_x_Metadata_sc_unique_track_id = train_gt_X[\n",
    "    \"Metadata_sc_unique_track_id\"\n",
    "].unique()\n",
    "val_df_x_Metadata_sc_unique_track_id = val_gt_X[\"Metadata_sc_unique_track_id\"].unique()\n",
    "test_df_x_Metadata_sc_unique_track_id = test_gt_X[\n",
    "    \"Metadata_sc_unique_track_id\"\n",
    "].unique()\n",
    "holdout_w_df_x_Metadata_sc_unique_track_id = holdout_w_gt_X[\n",
    "    \"Metadata_sc_unique_track_id\"\n",
    "].unique()\n",
    "print(\n",
    "    f\"train_df_x_Metadata_sc_unique_track_id shape: {train_df_x_Metadata_sc_unique_track_id.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"val_df_x_Metadata_sc_unique_track_id shape: {val_df_x_Metadata_sc_unique_track_id.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"test_df_x_Metadata_sc_unique_track_id shape: {test_df_x_Metadata_sc_unique_track_id.shape}\"\n",
    ")\n",
    "print(\n",
    "    f\"holdout_w_df_x_Metadata_sc_unique_track_id shape: {holdout_w_df_x_Metadata_sc_unique_track_id.shape}\"\n",
    ")\n",
    "# assertions :) make sure that the unique track ids are not overlapping\n",
    "assert set(train_df_x_Metadata_sc_unique_track_id).isdisjoint(\n",
    "    set(val_df_x_Metadata_sc_unique_track_id)\n",
    "), \"train and val track ids are overlapping\"\n",
    "assert set(train_df_x_Metadata_sc_unique_track_id).isdisjoint(\n",
    "    set(test_df_x_Metadata_sc_unique_track_id)\n",
    "), \"train and test track ids are overlapping\"\n",
    "assert set(train_df_x_Metadata_sc_unique_track_id).isdisjoint(\n",
    "    set(holdout_w_df_x_Metadata_sc_unique_track_id)\n",
    "), \"train and holdout track ids are overlapping\"\n",
    "assert set(val_df_x_Metadata_sc_unique_track_id).isdisjoint(\n",
    "    set(test_df_x_Metadata_sc_unique_track_id)\n",
    "), \"val and test track ids are overlapping\"\n",
    "assert set(val_df_x_Metadata_sc_unique_track_id).isdisjoint(\n",
    "    set(holdout_w_df_x_Metadata_sc_unique_track_id)\n",
    "), \"val and holdout track ids are overlapping\"\n",
    "assert set(test_df_x_Metadata_sc_unique_track_id).isdisjoint(\n",
    "    set(holdout_w_df_x_Metadata_sc_unique_track_id)\n",
    "), \"test and holdout track ids are overlapping\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y_gt shape: (367, 26), train_gt_X shape: (367, 2378)\n",
      "val_y_gt shape: (49, 26), val_gt_X shape: (49, 2378)\n",
      "test_y_gt shape: (49, 26), test_gt_X shape: (49, 2378)\n",
      "holdout_y_gt shape: (237, 26), holdout_gt_X shape: (237, 2378)\n"
     ]
    }
   ],
   "source": [
    "# find only the cell tracks that exist in the sc_profile\n",
    "train_gt_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        train_df_x_Metadata_sc_unique_track_id\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "val_gt_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        val_df_x_Metadata_sc_unique_track_id\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "test_gt_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        test_df_x_Metadata_sc_unique_track_id\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "holdout_gt_y = sc_endpoint_profile.loc[\n",
    "    sc_endpoint_profile[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        holdout_w_df_x_Metadata_sc_unique_track_id\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "\n",
    "# find only cell tracks that exist in the endpoint profile\n",
    "train_gt_X = train_gt_X.loc[\n",
    "    train_gt_X[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        train_gt_y[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "val_gt_X = val_gt_X.loc[\n",
    "    val_gt_X[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        val_gt_y[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "test_gt_X = test_gt_X.loc[\n",
    "    test_gt_X[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        test_gt_y[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "holdout_w_gt_X = holdout_w_gt_X.loc[\n",
    "    holdout_w_gt_X[\"Metadata_sc_unique_track_id\"].isin(\n",
    "        holdout_gt_y[\"Metadata_sc_unique_track_id\"]\n",
    "    )\n",
    "].drop_duplicates(\"Metadata_sc_unique_track_id\")\n",
    "\n",
    "print(f\"train_y_gt shape: {train_gt_y.shape}, train_gt_X shape: {train_gt_X.shape}\")\n",
    "print(f\"val_y_gt shape: {val_gt_y.shape}, val_gt_X shape: {val_gt_X.shape}\")\n",
    "print(f\"test_y_gt shape: {test_gt_y.shape}, test_gt_X shape: {test_gt_X.shape}\")\n",
    "print(\n",
    "    f\"holdout_y_gt shape: {holdout_gt_y.shape}, holdout_gt_X shape: {holdout_w_gt_X.shape}\"\n",
    ")\n",
    "# assertions :) make sure that the number of unique samples are the same\n",
    "assert (\n",
    "    train_gt_X.shape[0] == train_gt_y.shape[0]\n",
    "), \"train gt X and y shapes are not the same\"\n",
    "assert val_gt_X.shape[0] == val_gt_y.shape[0], \"val gt X and y shapes are not the same\"\n",
    "assert (\n",
    "    test_gt_X.shape[0] == test_gt_y.shape[0]\n",
    "), \"test gt X and y shapes are not the same\"\n",
    "assert (\n",
    "    holdout_w_gt_X.shape[0] == holdout_gt_y.shape[0]\n",
    "), \"holdout gt X and y shapes are not the same\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get metadata\n",
    "metadata_X_cols = [x for x in train_gt_X.columns if \"Metadata_\" in x]\n",
    "metadata_y_cols = [x for x in train_gt_y.columns if \"Metadata_\" in x]\n",
    "train_gt_X_metadata = train_gt_X[metadata_X_cols]\n",
    "train_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
    "val_gt_X_metadata = val_gt_X[metadata_X_cols]\n",
    "val_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
    "test_gt_X_metadata = test_gt_X[metadata_X_cols]\n",
    "test_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
    "holdout_w_gt_X_metadata = holdout_w_gt_X[metadata_X_cols]\n",
    "holdout_w_gt_X.drop(columns=metadata_X_cols, inplace=True)\n",
    "train_gt_y_metadata = train_gt_y[metadata_y_cols]\n",
    "train_gt_y.drop(columns=metadata_y_cols, inplace=True)\n",
    "val_gt_y_metadata = val_gt_y[metadata_y_cols]\n",
    "val_gt_y.drop(columns=metadata_y_cols, inplace=True)\n",
    "test_gt_y_metadata = test_gt_y[metadata_y_cols]\n",
    "test_gt_y.drop(columns=metadata_y_cols, inplace=True)\n",
    "holdout_w_gt_y_metadata = holdout_gt_y[metadata_y_cols]\n",
    "holdout_gt_y.drop(columns=metadata_y_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data\n",
    "shuffled_train_gt_X = train_gt_X.copy()\n",
    "for col in shuffled_train_gt_X.columns:\n",
    "    if col.startswith(\"Metadata_\"):\n",
    "        continue\n",
    "    shuffled_train_gt_X[col] = np.random.permutation(shuffled_train_gt_X[col].values)\n",
    "shuffled_val_gt_X = val_gt_X.copy()\n",
    "for col in shuffled_val_gt_X.columns:\n",
    "    if col.startswith(\"Metadata_\"):\n",
    "        continue\n",
    "    shuffled_val_gt_X[col] = np.random.permutation(shuffled_val_gt_X[col].values)\n",
    "shuffled_test_gt_X = test_gt_X.copy()\n",
    "for col in shuffled_test_gt_X.columns:\n",
    "    if col.startswith(\"Metadata_\"):\n",
    "        continue\n",
    "    shuffled_test_gt_X[col] = np.random.permutation(shuffled_test_gt_X[col].values)\n",
    "shuffled_holdout_w_gt_X = holdout_w_gt_X.copy()\n",
    "for col in shuffled_holdout_w_gt_X.columns:\n",
    "    if col.startswith(\"Metadata_\"):\n",
    "        continue\n",
    "    shuffled_holdout_w_gt_X[col] = np.random.permutation(\n",
    "        shuffled_holdout_w_gt_X[col].values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 2338\n",
      "n_outputs: 1\n",
      "n_metadata_features: 40\n"
     ]
    }
   ],
   "source": [
    "# number of input features\n",
    "n_features = train_gt_X.shape[1]\n",
    "# number of output features\n",
    "n_outputs = train_gt_y.shape[1]\n",
    "# number of metadata features\n",
    "n_metadata_features = train_gt_X_metadata.shape[1]\n",
    "\n",
    "print(f\"n_features: {n_features}\")\n",
    "print(f\"n_outputs: {n_outputs}\")\n",
    "print(f\"n_metadata_features: {n_metadata_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_of_train_tests = {\n",
    "    \"train\": {\n",
    "        \"X\": train_gt_X,\n",
    "        \"y\": train_gt_y,\n",
    "        \"metadata\": train_gt_X_metadata,\n",
    "        \"model_path\": [],\n",
    "    },\n",
    "    \"val\": {\n",
    "        \"X\": val_gt_X,\n",
    "        \"y\": val_gt_y,\n",
    "        \"metadata\": val_gt_X_metadata,\n",
    "        \"model_path\": [],\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"X\": test_gt_X,\n",
    "        \"y\": test_gt_y,\n",
    "        \"metadata\": test_gt_X_metadata,\n",
    "        \"model_path\": [],\n",
    "    },\n",
    "    \"train_shuffled\": {\n",
    "        \"X\": shuffled_train_gt_X,\n",
    "        \"y\": train_gt_y,\n",
    "        \"metadata\": train_gt_X_metadata,\n",
    "        \"model_path\": [],\n",
    "    },\n",
    "    \"val_shuffled\": {\n",
    "        \"X\": shuffled_val_gt_X,\n",
    "        \"y\": val_gt_y,\n",
    "        \"metadata\": val_gt_X_metadata,\n",
    "        \"model_path\": [],\n",
    "    },\n",
    "    \"test_shuffled\": {\n",
    "        \"X\": shuffled_test_gt_X,\n",
    "        \"y\": test_gt_y,\n",
    "        \"metadata\": test_gt_X_metadata,\n",
    "        \"model_path\": [],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Parameters()\n",
    "ml_configs = toml.load(\"../ML_utils/regression_class_config.toml\")\n",
    "mlp_params = parameter_set(params, ml_configs)\n",
    "mlp_params.IN_FEATURES = n_features\n",
    "mlp_params.OUT_FEATURES = n_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(367, 2338) (367, 1)\n",
      "(49, 2338) (49, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_gt_X.shape, train_gt_y.shape)\n",
    "print(val_gt_X.shape, val_gt_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(train_gt_X.values, dtype=torch.float32)\n",
    "y_train = torch.tensor(train_gt_y.values, dtype=torch.float32)\n",
    "X_val = torch.tensor(val_gt_X.values, dtype=torch.float32)\n",
    "y_val = torch.tensor(val_gt_y.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dtypes: torch.float32\n",
      "y_train dtypes: torch.float32\n",
      "X_val dtypes: torch.float32\n",
      "y_val dtypes: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# get the dtypes of the data\n",
    "print(f\"X_train dtypes: {X_train.dtype}\")\n",
    "print(f\"y_train dtypes: {y_train.dtype}\")\n",
    "print(f\"X_val dtypes: {X_val.dtype}\")\n",
    "print(f\"y_val dtypes: {y_val.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce data objects for train, val and test datasets\n",
    "train_data = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "val_data = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "\n",
    "\n",
    "# convert data class into a dataloader to be compatible with pytorch\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data, batch_size=mlp_params.HYPERPARAMETER_BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_data, batch_size=mlp_params.HYPERPARAMETER_BATCH_SIZE, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "pathlib.Path(\"../logs\").mkdir(parents=True, exist_ok=True)\n",
    "# Create a file handler\n",
    "file_handler = logging.FileHandler(\"../logs/optuna_log.txt\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Create a formatter and set it to the handler\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Optional: Set Optuna to use this logger\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "optuna.logging.enable_propagation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-12 13:52:12,389] A new study created in memory with name: no-name-aebb3aab-2bcd-495d-b21b-20f0b796a7cf\n",
      "[I 2025-05-12 13:52:14,254] Trial 0 finished with value: 0.612082588672638 and parameters: {'n_layers': 58, 'n_units_l0': 31, 'dropout_0': 0.3040015069161539, 'n_units_l1': 28, 'dropout_1': 0.10551745271223079, 'n_units_l2': 32, 'dropout_2': 0.2174107128637791, 'n_units_l3': 183, 'dropout_3': 0.3640073097187931, 'n_units_l4': 59, 'dropout_4': 0.08447978950790698, 'n_units_l5': 109, 'dropout_5': 0.1268825800516987, 'n_units_l6': 65, 'dropout_6': 0.13658965871267417, 'n_units_l7': 192, 'dropout_7': 0.10647019917460893, 'n_units_l8': 173, 'dropout_8': 0.13696573244684124, 'n_units_l9': 4, 'dropout_9': 0.19479129915731708, 'n_units_l10': 105, 'dropout_10': 0.13006042678111326, 'n_units_l11': 100, 'dropout_11': 0.18994580856144072, 'n_units_l12': 64, 'dropout_12': 0.3207724673188648, 'n_units_l13': 132, 'dropout_13': 0.37409704429853, 'n_units_l14': 78, 'dropout_14': 0.2120269877404608, 'n_units_l15': 138, 'dropout_15': 0.12675686139602763, 'n_units_l16': 167, 'dropout_16': 0.09827857586469216, 'n_units_l17': 7, 'dropout_17': 0.08415920064251883, 'n_units_l18': 40, 'dropout_18': 0.1487100801975989, 'n_units_l19': 134, 'dropout_19': 0.14461064541553117, 'n_units_l20': 164, 'dropout_20': 0.36095311647381106, 'n_units_l21': 79, 'dropout_21': 0.1086296814763639, 'n_units_l22': 196, 'dropout_22': 0.334894584128325, 'n_units_l23': 85, 'dropout_23': 0.2781810110157037, 'n_units_l24': 177, 'dropout_24': 0.3189323243196175, 'n_units_l25': 181, 'dropout_25': 0.21922150590991585, 'n_units_l26': 29, 'dropout_26': 0.24397287827206543, 'n_units_l27': 89, 'dropout_27': 0.32704264332284083, 'n_units_l28': 74, 'dropout_28': 0.20917010399732588, 'n_units_l29': 91, 'dropout_29': 0.06469670494025948, 'n_units_l30': 21, 'dropout_30': 0.1264971142742749, 'n_units_l31': 142, 'dropout_31': 0.39393449223765126, 'n_units_l32': 62, 'dropout_32': 0.09942679605200538, 'n_units_l33': 9, 'dropout_33': 0.28446463081120626, 'n_units_l34': 158, 'dropout_34': 0.29870339813952057, 'n_units_l35': 37, 'dropout_35': 0.12396046721274243, 'n_units_l36': 183, 'dropout_36': 0.057002583896521866, 'n_units_l37': 36, 'dropout_37': 0.10550180171336998, 'n_units_l38': 48, 'dropout_38': 0.06080285422979356, 'n_units_l39': 164, 'dropout_39': 0.09085197715866644, 'n_units_l40': 41, 'dropout_40': 0.22157053938255666, 'n_units_l41': 75, 'dropout_41': 0.3995847161273578, 'n_units_l42': 168, 'dropout_42': 0.2025280140431832, 'n_units_l43': 182, 'dropout_43': 0.39433840267982584, 'n_units_l44': 79, 'dropout_44': 0.24130681392661696, 'n_units_l45': 82, 'dropout_45': 0.31246980446134087, 'n_units_l46': 108, 'dropout_46': 0.09382021304308538, 'n_units_l47': 147, 'dropout_47': 0.19465420727650995, 'n_units_l48': 185, 'dropout_48': 0.1231900068232142, 'n_units_l49': 85, 'dropout_49': 0.34631564344453686, 'n_units_l50': 9, 'dropout_50': 0.05169971468873974, 'n_units_l51': 142, 'dropout_51': 0.08915243469818643, 'n_units_l52': 140, 'dropout_52': 0.3718298387557553, 'n_units_l53': 31, 'dropout_53': 0.06455428028049807, 'n_units_l54': 106, 'dropout_54': 0.2919410494483475, 'n_units_l55': 59, 'dropout_55': 0.3546497941034226, 'n_units_l56': 24, 'dropout_56': 0.09915647564775297, 'n_units_l57': 9, 'dropout_57': 0.1509802510031309, 'learning_rate': 0.004179892085724487, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.612082588672638.\n",
      "[I 2025-05-12 13:52:15,099] Trial 1 finished with value: 19282.668985927106 and parameters: {'n_layers': 32, 'n_units_l0': 68, 'dropout_0': 0.11292705935671989, 'n_units_l1': 73, 'dropout_1': 0.1418003373361267, 'n_units_l2': 19, 'dropout_2': 0.2746597355664032, 'n_units_l3': 127, 'dropout_3': 0.20504017467866104, 'n_units_l4': 171, 'dropout_4': 0.3687795018745653, 'n_units_l5': 4, 'dropout_5': 0.08318092363679569, 'n_units_l6': 161, 'dropout_6': 0.05051865329439931, 'n_units_l7': 184, 'dropout_7': 0.3916737535074667, 'n_units_l8': 92, 'dropout_8': 0.31019850401954, 'n_units_l9': 153, 'dropout_9': 0.3367570083885303, 'n_units_l10': 178, 'dropout_10': 0.31587102834862124, 'n_units_l11': 150, 'dropout_11': 0.0737210213642182, 'n_units_l12': 46, 'dropout_12': 0.1953799692573115, 'n_units_l13': 100, 'dropout_13': 0.37637392723032176, 'n_units_l14': 191, 'dropout_14': 0.20489206447055858, 'n_units_l15': 50, 'dropout_15': 0.2883895897730559, 'n_units_l16': 62, 'dropout_16': 0.3031043926973061, 'n_units_l17': 132, 'dropout_17': 0.14987134648056238, 'n_units_l18': 162, 'dropout_18': 0.343979203570605, 'n_units_l19': 96, 'dropout_19': 0.22998995689255436, 'n_units_l20': 86, 'dropout_20': 0.2456547523842032, 'n_units_l21': 156, 'dropout_21': 0.17094268843016525, 'n_units_l22': 40, 'dropout_22': 0.39163322324433364, 'n_units_l23': 76, 'dropout_23': 0.12241819292484922, 'n_units_l24': 101, 'dropout_24': 0.27557117599295394, 'n_units_l25': 2, 'dropout_25': 0.10647639625337377, 'n_units_l26': 127, 'dropout_26': 0.26932186545178893, 'n_units_l27': 106, 'dropout_27': 0.19872301711542995, 'n_units_l28': 42, 'dropout_28': 0.20905118947530021, 'n_units_l29': 82, 'dropout_29': 0.05001605557409108, 'n_units_l30': 70, 'dropout_30': 0.2019459511083691, 'n_units_l31': 84, 'dropout_31': 0.05069784131379603, 'learning_rate': 0.055078961866536914, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.612082588672638.\n",
      "[I 2025-05-12 13:52:15,364] Trial 2 finished with value: 258.3460283660889 and parameters: {'n_layers': 1, 'n_units_l0': 160, 'dropout_0': 0.1593602473137578, 'learning_rate': 0.05414673549338312, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.612082588672638.\n",
      "[I 2025-05-12 13:52:15,897] Trial 3 finished with value: 4.8040290248394015 and parameters: {'n_layers': 15, 'n_units_l0': 117, 'dropout_0': 0.3895602163407433, 'n_units_l1': 184, 'dropout_1': 0.0663383188895441, 'n_units_l2': 86, 'dropout_2': 0.15104947565390758, 'n_units_l3': 40, 'dropout_3': 0.32684861820484856, 'n_units_l4': 161, 'dropout_4': 0.2530949580179691, 'n_units_l5': 86, 'dropout_5': 0.2008664359713293, 'n_units_l6': 134, 'dropout_6': 0.1764746258903157, 'n_units_l7': 61, 'dropout_7': 0.1357863991139266, 'n_units_l8': 189, 'dropout_8': 0.35836215699012247, 'n_units_l9': 52, 'dropout_9': 0.35895687462721876, 'n_units_l10': 95, 'dropout_10': 0.10765821016835819, 'n_units_l11': 112, 'dropout_11': 0.0550874659259716, 'n_units_l12': 168, 'dropout_12': 0.3124452475072705, 'n_units_l13': 11, 'dropout_13': 0.3056855175079596, 'n_units_l14': 193, 'dropout_14': 0.2425153793625615, 'learning_rate': 0.0067582353426157964, 'optimizer': 'RMSprop'}. Best is trial 0 with value: 0.612082588672638.\n",
      "[I 2025-05-12 13:52:17,019] Trial 4 finished with value: 0.563153862953186 and parameters: {'n_layers': 52, 'n_units_l0': 109, 'dropout_0': 0.38863134353459927, 'n_units_l1': 94, 'dropout_1': 0.17358291746217977, 'n_units_l2': 55, 'dropout_2': 0.17336488225288638, 'n_units_l3': 56, 'dropout_3': 0.13979435881388458, 'n_units_l4': 2, 'dropout_4': 0.17539766656033934, 'n_units_l5': 43, 'dropout_5': 0.2461484500067272, 'n_units_l6': 125, 'dropout_6': 0.2656706847085604, 'n_units_l7': 37, 'dropout_7': 0.20620051398534, 'n_units_l8': 49, 'dropout_8': 0.3507976412373205, 'n_units_l9': 47, 'dropout_9': 0.3516448333576399, 'n_units_l10': 94, 'dropout_10': 0.07318113692498984, 'n_units_l11': 147, 'dropout_11': 0.09243558619926223, 'n_units_l12': 133, 'dropout_12': 0.19594019621156622, 'n_units_l13': 173, 'dropout_13': 0.13481375872453183, 'n_units_l14': 54, 'dropout_14': 0.33442598532013795, 'n_units_l15': 72, 'dropout_15': 0.21201286122780688, 'n_units_l16': 36, 'dropout_16': 0.3462553981034094, 'n_units_l17': 34, 'dropout_17': 0.319811115679716, 'n_units_l18': 129, 'dropout_18': 0.321613083861134, 'n_units_l19': 111, 'dropout_19': 0.11413981107875332, 'n_units_l20': 92, 'dropout_20': 0.3263767483088939, 'n_units_l21': 67, 'dropout_21': 0.3345480650453324, 'n_units_l22': 114, 'dropout_22': 0.3594455125860594, 'n_units_l23': 174, 'dropout_23': 0.07529905542885561, 'n_units_l24': 80, 'dropout_24': 0.1039669511970119, 'n_units_l25': 59, 'dropout_25': 0.06918031235925524, 'n_units_l26': 101, 'dropout_26': 0.14346313299042615, 'n_units_l27': 119, 'dropout_27': 0.23193127458531798, 'n_units_l28': 134, 'dropout_28': 0.27654173581690045, 'n_units_l29': 131, 'dropout_29': 0.3832065050291233, 'n_units_l30': 113, 'dropout_30': 0.1520430841729108, 'n_units_l31': 104, 'dropout_31': 0.059419554409478534, 'n_units_l32': 119, 'dropout_32': 0.345731006323524, 'n_units_l33': 95, 'dropout_33': 0.1485882179951009, 'n_units_l34': 84, 'dropout_34': 0.24102117936123524, 'n_units_l35': 66, 'dropout_35': 0.2693942595203034, 'n_units_l36': 63, 'dropout_36': 0.29051013951920024, 'n_units_l37': 151, 'dropout_37': 0.1785159422361639, 'n_units_l38': 174, 'dropout_38': 0.3585993950535847, 'n_units_l39': 186, 'dropout_39': 0.06323816171941894, 'n_units_l40': 44, 'dropout_40': 0.08263962279991444, 'n_units_l41': 151, 'dropout_41': 0.12327254208659708, 'n_units_l42': 129, 'dropout_42': 0.31300955222487414, 'n_units_l43': 158, 'dropout_43': 0.2594990488392835, 'n_units_l44': 66, 'dropout_44': 0.30884829875889686, 'n_units_l45': 145, 'dropout_45': 0.0758339180108172, 'n_units_l46': 145, 'dropout_46': 0.1429477578959915, 'n_units_l47': 102, 'dropout_47': 0.39428780970441996, 'n_units_l48': 110, 'dropout_48': 0.25808049964243246, 'n_units_l49': 22, 'dropout_49': 0.053276890464035616, 'n_units_l50': 101, 'dropout_50': 0.28883374768911013, 'n_units_l51': 124, 'dropout_51': 0.2423102828413028, 'learning_rate': 0.018644331334509604, 'optimizer': 'SGD'}. Best is trial 4 with value: 0.563153862953186.\n",
      "[I 2025-05-12 13:52:18,767] Trial 5 finished with value: 0.5590697479248047 and parameters: {'n_layers': 81, 'n_units_l0': 148, 'dropout_0': 0.12180844898022837, 'n_units_l1': 60, 'dropout_1': 0.08178369950157492, 'n_units_l2': 15, 'dropout_2': 0.3909985152789103, 'n_units_l3': 123, 'dropout_3': 0.06443407665599914, 'n_units_l4': 64, 'dropout_4': 0.2105359231054561, 'n_units_l5': 96, 'dropout_5': 0.15729535192990157, 'n_units_l6': 76, 'dropout_6': 0.28800600340639415, 'n_units_l7': 165, 'dropout_7': 0.20538235347586364, 'n_units_l8': 41, 'dropout_8': 0.15688984817604087, 'n_units_l9': 145, 'dropout_9': 0.3585686939992972, 'n_units_l10': 58, 'dropout_10': 0.31228241690409575, 'n_units_l11': 5, 'dropout_11': 0.33553965358795085, 'n_units_l12': 169, 'dropout_12': 0.3082627967463509, 'n_units_l13': 60, 'dropout_13': 0.3540205398337744, 'n_units_l14': 103, 'dropout_14': 0.34209389468257295, 'n_units_l15': 58, 'dropout_15': 0.31151103005302705, 'n_units_l16': 86, 'dropout_16': 0.39225674772783775, 'n_units_l17': 169, 'dropout_17': 0.14888093722743578, 'n_units_l18': 25, 'dropout_18': 0.3092642712094856, 'n_units_l19': 137, 'dropout_19': 0.1812415106044355, 'n_units_l20': 66, 'dropout_20': 0.3540705937078804, 'n_units_l21': 82, 'dropout_21': 0.3172252721501409, 'n_units_l22': 72, 'dropout_22': 0.21700592497780463, 'n_units_l23': 138, 'dropout_23': 0.06522764073890473, 'n_units_l24': 200, 'dropout_24': 0.3931488232055643, 'n_units_l25': 75, 'dropout_25': 0.19657328938183372, 'n_units_l26': 71, 'dropout_26': 0.18238912290648168, 'n_units_l27': 128, 'dropout_27': 0.17423037320538298, 'n_units_l28': 164, 'dropout_28': 0.39925818962779935, 'n_units_l29': 150, 'dropout_29': 0.27715752482638834, 'n_units_l30': 122, 'dropout_30': 0.08610758366754097, 'n_units_l31': 163, 'dropout_31': 0.37536626479969537, 'n_units_l32': 174, 'dropout_32': 0.3175810662118302, 'n_units_l33': 148, 'dropout_33': 0.2836984351309243, 'n_units_l34': 12, 'dropout_34': 0.20986090302853982, 'n_units_l35': 173, 'dropout_35': 0.25248963963881776, 'n_units_l36': 163, 'dropout_36': 0.22195178092771128, 'n_units_l37': 90, 'dropout_37': 0.19524198231108064, 'n_units_l38': 94, 'dropout_38': 0.05522827552756915, 'n_units_l39': 163, 'dropout_39': 0.383939516218074, 'n_units_l40': 154, 'dropout_40': 0.22985880367049044, 'n_units_l41': 169, 'dropout_41': 0.3759556976794589, 'n_units_l42': 133, 'dropout_42': 0.27643081176611906, 'n_units_l43': 165, 'dropout_43': 0.3327614802006242, 'n_units_l44': 166, 'dropout_44': 0.3725516863839215, 'n_units_l45': 71, 'dropout_45': 0.2963809082832736, 'n_units_l46': 90, 'dropout_46': 0.10996273432910375, 'n_units_l47': 37, 'dropout_47': 0.2357583721318381, 'n_units_l48': 75, 'dropout_48': 0.18311287505350765, 'n_units_l49': 127, 'dropout_49': 0.3757930619154731, 'n_units_l50': 92, 'dropout_50': 0.13011160444278708, 'n_units_l51': 200, 'dropout_51': 0.15191728598755008, 'n_units_l52': 100, 'dropout_52': 0.06191610995910442, 'n_units_l53': 133, 'dropout_53': 0.11622681563560269, 'n_units_l54': 121, 'dropout_54': 0.23764187547401594, 'n_units_l55': 148, 'dropout_55': 0.18039644915901104, 'n_units_l56': 164, 'dropout_56': 0.3329007183882835, 'n_units_l57': 62, 'dropout_57': 0.27368994507289157, 'n_units_l58': 19, 'dropout_58': 0.19841836582797628, 'n_units_l59': 10, 'dropout_59': 0.09354373092861176, 'n_units_l60': 58, 'dropout_60': 0.11297487847746808, 'n_units_l61': 111, 'dropout_61': 0.11618897568507262, 'n_units_l62': 138, 'dropout_62': 0.1736435036076368, 'n_units_l63': 111, 'dropout_63': 0.356667463515502, 'n_units_l64': 96, 'dropout_64': 0.20438568297849213, 'n_units_l65': 139, 'dropout_65': 0.2028509979567929, 'n_units_l66': 70, 'dropout_66': 0.19335157286752558, 'n_units_l67': 71, 'dropout_67': 0.20738194163128865, 'n_units_l68': 69, 'dropout_68': 0.3823343895230445, 'n_units_l69': 178, 'dropout_69': 0.09737518390680425, 'n_units_l70': 134, 'dropout_70': 0.1399584478661796, 'n_units_l71': 183, 'dropout_71': 0.1679476543226829, 'n_units_l72': 98, 'dropout_72': 0.21778093897261164, 'n_units_l73': 183, 'dropout_73': 0.3566289672124706, 'n_units_l74': 169, 'dropout_74': 0.07601945004763942, 'n_units_l75': 190, 'dropout_75': 0.18838124793503447, 'n_units_l76': 76, 'dropout_76': 0.301439934869945, 'n_units_l77': 40, 'dropout_77': 0.36926586021466823, 'n_units_l78': 169, 'dropout_78': 0.36204132246357756, 'n_units_l79': 95, 'dropout_79': 0.33539528393771806, 'n_units_l80': 64, 'dropout_80': 0.20143693489704007, 'learning_rate': 0.07525089636315731, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.5590697479248047.\n",
      "[I 2025-05-12 13:52:18,839] Trial 6 pruned. \n",
      "[I 2025-05-12 13:52:21,110] Trial 7 finished with value: 0.5607776296138763 and parameters: {'n_layers': 93, 'n_units_l0': 79, 'dropout_0': 0.23972828318391187, 'n_units_l1': 147, 'dropout_1': 0.3796576473755013, 'n_units_l2': 63, 'dropout_2': 0.36991282128465935, 'n_units_l3': 16, 'dropout_3': 0.38554303476305596, 'n_units_l4': 148, 'dropout_4': 0.22917157695102802, 'n_units_l5': 75, 'dropout_5': 0.28252606625065313, 'n_units_l6': 80, 'dropout_6': 0.37672226585159146, 'n_units_l7': 88, 'dropout_7': 0.16872352873924357, 'n_units_l8': 136, 'dropout_8': 0.14839259869926594, 'n_units_l9': 125, 'dropout_9': 0.27076063548606444, 'n_units_l10': 98, 'dropout_10': 0.1051772900325427, 'n_units_l11': 117, 'dropout_11': 0.10666598776619718, 'n_units_l12': 97, 'dropout_12': 0.06292169746204138, 'n_units_l13': 14, 'dropout_13': 0.23521315729189246, 'n_units_l14': 23, 'dropout_14': 0.3404064317667412, 'n_units_l15': 196, 'dropout_15': 0.21887168202688118, 'n_units_l16': 129, 'dropout_16': 0.30175592070235274, 'n_units_l17': 28, 'dropout_17': 0.15104484990330236, 'n_units_l18': 53, 'dropout_18': 0.07231942097744767, 'n_units_l19': 143, 'dropout_19': 0.29010671083489725, 'n_units_l20': 181, 'dropout_20': 0.36380707696295456, 'n_units_l21': 168, 'dropout_21': 0.22662225561278093, 'n_units_l22': 9, 'dropout_22': 0.0649227724355104, 'n_units_l23': 135, 'dropout_23': 0.2401660643305012, 'n_units_l24': 85, 'dropout_24': 0.29630518534947714, 'n_units_l25': 17, 'dropout_25': 0.28237142470406756, 'n_units_l26': 181, 'dropout_26': 0.28984767264153694, 'n_units_l27': 195, 'dropout_27': 0.3828672051403687, 'n_units_l28': 129, 'dropout_28': 0.08930357549769027, 'n_units_l29': 79, 'dropout_29': 0.10841322571264554, 'n_units_l30': 124, 'dropout_30': 0.3725151898946866, 'n_units_l31': 71, 'dropout_31': 0.13734950563016923, 'n_units_l32': 54, 'dropout_32': 0.09990727658491624, 'n_units_l33': 27, 'dropout_33': 0.09563723905471228, 'n_units_l34': 15, 'dropout_34': 0.25832318366431384, 'n_units_l35': 56, 'dropout_35': 0.26267298479074114, 'n_units_l36': 39, 'dropout_36': 0.15345546630068807, 'n_units_l37': 172, 'dropout_37': 0.29682257353725255, 'n_units_l38': 89, 'dropout_38': 0.1940458459102159, 'n_units_l39': 171, 'dropout_39': 0.27771356480063836, 'n_units_l40': 180, 'dropout_40': 0.2563593097009634, 'n_units_l41': 11, 'dropout_41': 0.0556502113841365, 'n_units_l42': 12, 'dropout_42': 0.29128517215535665, 'n_units_l43': 183, 'dropout_43': 0.24546746869238217, 'n_units_l44': 178, 'dropout_44': 0.2733316380985177, 'n_units_l45': 46, 'dropout_45': 0.11345055357746948, 'n_units_l46': 26, 'dropout_46': 0.38225577989349396, 'n_units_l47': 167, 'dropout_47': 0.11451686270577525, 'n_units_l48': 134, 'dropout_48': 0.15890782987014557, 'n_units_l49': 78, 'dropout_49': 0.22513358189713178, 'n_units_l50': 70, 'dropout_50': 0.3249379724610748, 'n_units_l51': 194, 'dropout_51': 0.08144983669494588, 'n_units_l52': 128, 'dropout_52': 0.06382622367639683, 'n_units_l53': 164, 'dropout_53': 0.12953195508330853, 'n_units_l54': 110, 'dropout_54': 0.3572904464747592, 'n_units_l55': 180, 'dropout_55': 0.13499492912329672, 'n_units_l56': 180, 'dropout_56': 0.3281688060089112, 'n_units_l57': 7, 'dropout_57': 0.28094911658557464, 'n_units_l58': 114, 'dropout_58': 0.12276370229432264, 'n_units_l59': 23, 'dropout_59': 0.1200391466154376, 'n_units_l60': 25, 'dropout_60': 0.19751674613142584, 'n_units_l61': 31, 'dropout_61': 0.33244943802584637, 'n_units_l62': 28, 'dropout_62': 0.14258392115377347, 'n_units_l63': 108, 'dropout_63': 0.14036393937758657, 'n_units_l64': 81, 'dropout_64': 0.14778124705381573, 'n_units_l65': 84, 'dropout_65': 0.23271651365076618, 'n_units_l66': 30, 'dropout_66': 0.38353491136384177, 'n_units_l67': 153, 'dropout_67': 0.10229482552915684, 'n_units_l68': 184, 'dropout_68': 0.08276116760778421, 'n_units_l69': 198, 'dropout_69': 0.22698782142223578, 'n_units_l70': 189, 'dropout_70': 0.12271429846974563, 'n_units_l71': 16, 'dropout_71': 0.05430111361935638, 'n_units_l72': 167, 'dropout_72': 0.397615422383996, 'n_units_l73': 45, 'dropout_73': 0.23624164620112992, 'n_units_l74': 45, 'dropout_74': 0.2276451463886196, 'n_units_l75': 177, 'dropout_75': 0.24187152091021508, 'n_units_l76': 77, 'dropout_76': 0.2669773579785361, 'n_units_l77': 50, 'dropout_77': 0.1717020187401309, 'n_units_l78': 176, 'dropout_78': 0.20945294857767133, 'n_units_l79': 172, 'dropout_79': 0.20258031811444688, 'n_units_l80': 185, 'dropout_80': 0.2660888313690782, 'n_units_l81': 158, 'dropout_81': 0.17015386717036235, 'n_units_l82': 168, 'dropout_82': 0.31121280719713285, 'n_units_l83': 43, 'dropout_83': 0.0969693250086515, 'n_units_l84': 128, 'dropout_84': 0.3803653740672123, 'n_units_l85': 96, 'dropout_85': 0.25126278519913886, 'n_units_l86': 94, 'dropout_86': 0.39818693913422143, 'n_units_l87': 47, 'dropout_87': 0.36256083468183514, 'n_units_l88': 79, 'dropout_88': 0.20179022765274396, 'n_units_l89': 170, 'dropout_89': 0.24073559206134854, 'n_units_l90': 90, 'dropout_90': 0.12432896758497979, 'n_units_l91': 97, 'dropout_91': 0.3939971673575592, 'n_units_l92': 92, 'dropout_92': 0.23119812000239853, 'learning_rate': 0.02222607115311746, 'optimizer': 'Adam'}. Best is trial 5 with value: 0.5590697479248047.\n",
      "[I 2025-05-12 13:52:22,971] Trial 8 finished with value: 0.5636858260631561 and parameters: {'n_layers': 96, 'n_units_l0': 95, 'dropout_0': 0.35330636195966114, 'n_units_l1': 147, 'dropout_1': 0.15232893459555386, 'n_units_l2': 142, 'dropout_2': 0.25704521310538725, 'n_units_l3': 26, 'dropout_3': 0.10601706101903083, 'n_units_l4': 61, 'dropout_4': 0.24289815405537546, 'n_units_l5': 15, 'dropout_5': 0.07831122865354574, 'n_units_l6': 185, 'dropout_6': 0.23136753019786577, 'n_units_l7': 152, 'dropout_7': 0.24905761126910403, 'n_units_l8': 23, 'dropout_8': 0.12388252395153702, 'n_units_l9': 32, 'dropout_9': 0.2922551235320858, 'n_units_l10': 196, 'dropout_10': 0.0635368779672666, 'n_units_l11': 187, 'dropout_11': 0.06431055479434875, 'n_units_l12': 110, 'dropout_12': 0.11535234830787532, 'n_units_l13': 166, 'dropout_13': 0.09114965757010601, 'n_units_l14': 34, 'dropout_14': 0.10456477754947077, 'n_units_l15': 30, 'dropout_15': 0.1384990977571569, 'n_units_l16': 33, 'dropout_16': 0.13773507718480552, 'n_units_l17': 170, 'dropout_17': 0.07496561170668856, 'n_units_l18': 152, 'dropout_18': 0.25505947124324985, 'n_units_l19': 200, 'dropout_19': 0.24062017519971501, 'n_units_l20': 105, 'dropout_20': 0.10348990615426845, 'n_units_l21': 134, 'dropout_21': 0.3523237738551203, 'n_units_l22': 119, 'dropout_22': 0.27769657474677706, 'n_units_l23': 50, 'dropout_23': 0.22460463431050592, 'n_units_l24': 68, 'dropout_24': 0.1492807991909244, 'n_units_l25': 43, 'dropout_25': 0.0564117105135136, 'n_units_l26': 36, 'dropout_26': 0.13267545779604556, 'n_units_l27': 22, 'dropout_27': 0.2621733104829963, 'n_units_l28': 57, 'dropout_28': 0.227209573974067, 'n_units_l29': 187, 'dropout_29': 0.24416445148570154, 'n_units_l30': 87, 'dropout_30': 0.12422738000533692, 'n_units_l31': 16, 'dropout_31': 0.3847187308553315, 'n_units_l32': 193, 'dropout_32': 0.052854076685190286, 'n_units_l33': 163, 'dropout_33': 0.15897936051345277, 'n_units_l34': 29, 'dropout_34': 0.1934239768412459, 'n_units_l35': 73, 'dropout_35': 0.09640453440729904, 'n_units_l36': 42, 'dropout_36': 0.3036352357564156, 'n_units_l37': 9, 'dropout_37': 0.23689292185735228, 'n_units_l38': 143, 'dropout_38': 0.123855713301044, 'n_units_l39': 72, 'dropout_39': 0.11053911783464931, 'n_units_l40': 70, 'dropout_40': 0.17433256026900368, 'n_units_l41': 48, 'dropout_41': 0.14875737393230604, 'n_units_l42': 99, 'dropout_42': 0.2774013067304226, 'n_units_l43': 70, 'dropout_43': 0.3634425758602544, 'n_units_l44': 174, 'dropout_44': 0.22745963804165387, 'n_units_l45': 80, 'dropout_45': 0.14189385566511276, 'n_units_l46': 159, 'dropout_46': 0.15894294368815726, 'n_units_l47': 184, 'dropout_47': 0.08720694360613232, 'n_units_l48': 93, 'dropout_48': 0.27714625037525203, 'n_units_l49': 18, 'dropout_49': 0.3598419151783529, 'n_units_l50': 54, 'dropout_50': 0.13745339160612458, 'n_units_l51': 145, 'dropout_51': 0.2847082757601494, 'n_units_l52': 132, 'dropout_52': 0.3406223944841756, 'n_units_l53': 164, 'dropout_53': 0.3000140292466976, 'n_units_l54': 116, 'dropout_54': 0.3212254352229581, 'n_units_l55': 121, 'dropout_55': 0.16595417363946577, 'n_units_l56': 7, 'dropout_56': 0.08342373987804422, 'n_units_l57': 118, 'dropout_57': 0.29160640114324854, 'n_units_l58': 88, 'dropout_58': 0.3864800857547929, 'n_units_l59': 182, 'dropout_59': 0.08398465089270185, 'n_units_l60': 41, 'dropout_60': 0.351065758089007, 'n_units_l61': 157, 'dropout_61': 0.0641661843819257, 'n_units_l62': 31, 'dropout_62': 0.1166259829080376, 'n_units_l63': 36, 'dropout_63': 0.17066086426989308, 'n_units_l64': 186, 'dropout_64': 0.1556286159084217, 'n_units_l65': 62, 'dropout_65': 0.3763717228245858, 'n_units_l66': 198, 'dropout_66': 0.35486809257579605, 'n_units_l67': 7, 'dropout_67': 0.16503600384226197, 'n_units_l68': 39, 'dropout_68': 0.10572672303361699, 'n_units_l69': 15, 'dropout_69': 0.34190719689672167, 'n_units_l70': 136, 'dropout_70': 0.15426106623526353, 'n_units_l71': 129, 'dropout_71': 0.29953390080757414, 'n_units_l72': 38, 'dropout_72': 0.16712195364936355, 'n_units_l73': 44, 'dropout_73': 0.20935596209403018, 'n_units_l74': 55, 'dropout_74': 0.09134737768940321, 'n_units_l75': 64, 'dropout_75': 0.11488954565102528, 'n_units_l76': 147, 'dropout_76': 0.15626485780322275, 'n_units_l77': 173, 'dropout_77': 0.11466661503745544, 'n_units_l78': 106, 'dropout_78': 0.18798133882324353, 'n_units_l79': 58, 'dropout_79': 0.10938160574112196, 'n_units_l80': 44, 'dropout_80': 0.12602591935890914, 'n_units_l81': 28, 'dropout_81': 0.2570265814023303, 'n_units_l82': 116, 'dropout_82': 0.2448204966929559, 'n_units_l83': 53, 'dropout_83': 0.08137844935503788, 'n_units_l84': 105, 'dropout_84': 0.20453238899097081, 'n_units_l85': 35, 'dropout_85': 0.32205655386426174, 'n_units_l86': 160, 'dropout_86': 0.08619513210815048, 'n_units_l87': 4, 'dropout_87': 0.08326594064954479, 'n_units_l88': 103, 'dropout_88': 0.09341146568098568, 'n_units_l89': 99, 'dropout_89': 0.27274837552970943, 'n_units_l90': 10, 'dropout_90': 0.20509011459801346, 'n_units_l91': 134, 'dropout_91': 0.2007819910596199, 'n_units_l92': 135, 'dropout_92': 0.215799812276188, 'n_units_l93': 54, 'dropout_93': 0.2731023656795396, 'n_units_l94': 112, 'dropout_94': 0.061742147683295306, 'n_units_l95': 27, 'dropout_95': 0.3429252334246373, 'learning_rate': 0.03893653158909601, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.5590697479248047.\n",
      "[I 2025-05-12 13:52:24,631] Trial 9 finished with value: 0.5603642833232879 and parameters: {'n_layers': 81, 'n_units_l0': 124, 'dropout_0': 0.1156249171522855, 'n_units_l1': 108, 'dropout_1': 0.07336774968926744, 'n_units_l2': 115, 'dropout_2': 0.14042449171369542, 'n_units_l3': 37, 'dropout_3': 0.1638656177758158, 'n_units_l4': 6, 'dropout_4': 0.2451093211079069, 'n_units_l5': 177, 'dropout_5': 0.18514224953501096, 'n_units_l6': 8, 'dropout_6': 0.12407132251491598, 'n_units_l7': 5, 'dropout_7': 0.07349237834841466, 'n_units_l8': 128, 'dropout_8': 0.1846798624021831, 'n_units_l9': 148, 'dropout_9': 0.1490452768988194, 'n_units_l10': 50, 'dropout_10': 0.16064043300207037, 'n_units_l11': 108, 'dropout_11': 0.3094225887051712, 'n_units_l12': 52, 'dropout_12': 0.35749158770385187, 'n_units_l13': 103, 'dropout_13': 0.27396861904469455, 'n_units_l14': 46, 'dropout_14': 0.2656045894190281, 'n_units_l15': 157, 'dropout_15': 0.0984729329477162, 'n_units_l16': 93, 'dropout_16': 0.3701586548733554, 'n_units_l17': 169, 'dropout_17': 0.33410157512567246, 'n_units_l18': 17, 'dropout_18': 0.10916411438540552, 'n_units_l19': 200, 'dropout_19': 0.3452556822888806, 'n_units_l20': 188, 'dropout_20': 0.11485834785833007, 'n_units_l21': 122, 'dropout_21': 0.1779446124378637, 'n_units_l22': 113, 'dropout_22': 0.37316471070930696, 'n_units_l23': 69, 'dropout_23': 0.22239182475697494, 'n_units_l24': 154, 'dropout_24': 0.18039789396818812, 'n_units_l25': 23, 'dropout_25': 0.08362905746335222, 'n_units_l26': 156, 'dropout_26': 0.14268484241850074, 'n_units_l27': 139, 'dropout_27': 0.20981413980306313, 'n_units_l28': 39, 'dropout_28': 0.34182148001433194, 'n_units_l29': 195, 'dropout_29': 0.1642243200883384, 'n_units_l30': 15, 'dropout_30': 0.14543460085781001, 'n_units_l31': 113, 'dropout_31': 0.3978640387572855, 'n_units_l32': 48, 'dropout_32': 0.27313819584430904, 'n_units_l33': 157, 'dropout_33': 0.1615323887372338, 'n_units_l34': 24, 'dropout_34': 0.11355983564404727, 'n_units_l35': 173, 'dropout_35': 0.17146717056795166, 'n_units_l36': 140, 'dropout_36': 0.2733566796012033, 'n_units_l37': 72, 'dropout_37': 0.10912552951450984, 'n_units_l38': 101, 'dropout_38': 0.2098820208824954, 'n_units_l39': 25, 'dropout_39': 0.3333317353976315, 'n_units_l40': 141, 'dropout_40': 0.1408735337414161, 'n_units_l41': 155, 'dropout_41': 0.38227387453483097, 'n_units_l42': 197, 'dropout_42': 0.21769215557728983, 'n_units_l43': 14, 'dropout_43': 0.19140932523377163, 'n_units_l44': 102, 'dropout_44': 0.1478730818594871, 'n_units_l45': 11, 'dropout_45': 0.05760293153584285, 'n_units_l46': 72, 'dropout_46': 0.388449009201969, 'n_units_l47': 39, 'dropout_47': 0.1561132406528115, 'n_units_l48': 181, 'dropout_48': 0.16743300894971075, 'n_units_l49': 5, 'dropout_49': 0.14019940543638038, 'n_units_l50': 119, 'dropout_50': 0.18511229701117393, 'n_units_l51': 138, 'dropout_51': 0.34267051045604374, 'n_units_l52': 150, 'dropout_52': 0.27096875360106365, 'n_units_l53': 77, 'dropout_53': 0.15141761904886394, 'n_units_l54': 149, 'dropout_54': 0.22569450187829504, 'n_units_l55': 162, 'dropout_55': 0.09318291926575326, 'n_units_l56': 107, 'dropout_56': 0.1424725061205186, 'n_units_l57': 7, 'dropout_57': 0.05674755620601075, 'n_units_l58': 160, 'dropout_58': 0.08716982654358843, 'n_units_l59': 105, 'dropout_59': 0.394472895918469, 'n_units_l60': 121, 'dropout_60': 0.1565722362412087, 'n_units_l61': 178, 'dropout_61': 0.17700862118546373, 'n_units_l62': 9, 'dropout_62': 0.26891963590111534, 'n_units_l63': 35, 'dropout_63': 0.09236857539150742, 'n_units_l64': 172, 'dropout_64': 0.1640821645627313, 'n_units_l65': 51, 'dropout_65': 0.07548878597101856, 'n_units_l66': 32, 'dropout_66': 0.2898505073458449, 'n_units_l67': 16, 'dropout_67': 0.10065081383103347, 'n_units_l68': 34, 'dropout_68': 0.1844692907756202, 'n_units_l69': 168, 'dropout_69': 0.06268732707044017, 'n_units_l70': 47, 'dropout_70': 0.14776492078787076, 'n_units_l71': 57, 'dropout_71': 0.14926404200463508, 'n_units_l72': 66, 'dropout_72': 0.24308026145707673, 'n_units_l73': 128, 'dropout_73': 0.15220932815296015, 'n_units_l74': 118, 'dropout_74': 0.14425932495607566, 'n_units_l75': 78, 'dropout_75': 0.13346647246098914, 'n_units_l76': 20, 'dropout_76': 0.0637246273776273, 'n_units_l77': 184, 'dropout_77': 0.13499782215076736, 'n_units_l78': 118, 'dropout_78': 0.10545949949929094, 'n_units_l79': 174, 'dropout_79': 0.36164908109650573, 'n_units_l80': 182, 'dropout_80': 0.11044118494458685, 'learning_rate': 0.010537454578590223, 'optimizer': 'SGD'}. Best is trial 5 with value: 0.5590697479248047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.558585776090622\n",
      "Training Loss: 1.3985924863815307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.558585776090622, 1.3985924863815307)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wrap the objective function inside of a lambda function to pass args...\n",
    "objective_lambda_func = lambda trial: objective_model_optimizer(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    trial=trial,\n",
    "    params=params,\n",
    "    metric=mlp_params.METRIC,\n",
    "    return_info=False,\n",
    ")\n",
    "# Study is the object for model optimization\n",
    "study = optuna.create_study(\n",
    "    direction=f\"{mlp_params.DIRECTION}\",\n",
    "    sampler=RandomSampler(),\n",
    "    study_name=\"live_cell_AnnexinV_prediction\",\n",
    ")\n",
    "# Here I apply the optimize function of the study to the objective function\n",
    "# This optimizes each parameter specified to be optimized from the defined search space\n",
    "study.optimize(objective_lambda_func, n_trials=mlp_params.N_TRIALS)\n",
    "# Prints out the best trial's optimized parameters\n",
    "objective_model_optimizer(\n",
    "    train_loader,\n",
    "    valid_loader,\n",
    "    trial=study.best_trial,\n",
    "    params=params,\n",
    "    metric=mlp_params.METRIC,\n",
    "    return_info=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Cells_Intensity_MeanIntensityEdge_AnnexinV\"\n",
    "param_dict = extract_best_trial_params(study.best_params, params, model_name=model_name)\n",
    "\n",
    "\n",
    "untrained_model_archetecture_only = optimized_model_create(\n",
    "    params=params,\n",
    "    model_name=model_name,\n",
    ")\n",
    "# save the blank model architecture\n",
    "model_path = f\"../models/{model_name}.pt\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
