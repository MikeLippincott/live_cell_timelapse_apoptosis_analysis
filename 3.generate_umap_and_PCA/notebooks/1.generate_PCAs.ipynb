{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_pca_to_the_first_timepoint(\n",
    "    df: pd.DataFrame,\n",
    "    timepoint_column: str,\n",
    "    metadata_columns: list,\n",
    "    feature_columns: list,\n",
    "    pca_model: PCA,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    This function fits a pca model to the first timepoint of the data and then applies the model to the rest of the data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The dataframe containing all feature, metadata, and timepoint columns.\n",
    "    timepoint_column : str\n",
    "        The name of the column containing the timepoint information\n",
    "    metadata_columns : list\n",
    "        The names of the columns containing the metadata information\n",
    "    feature_columns : list\n",
    "        The names of the columns containing the feature information\n",
    "    pca_model : pca.pca\n",
    "        The pca model to use\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The pca embeddings for the data, with the metadata columns included.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    metadata_df = df[metadata_columns]\n",
    "\n",
    "    # get the first timepoint and the subset of the data for that timepoint\n",
    "    first_time = df[timepoint_column].min()\n",
    "    first_timepoint_subset_df = df[df[timepoint_column] == first_time]\n",
    "\n",
    "    # Prepare the first timepoint subset by dropping metadata columns, selecting feature columns, and removing rows with missing values\n",
    "    first_timepoint_subset_df = first_timepoint_subset_df.drop(metadata_columns, axis=1)\n",
    "    first_timepoint_subset_df = first_timepoint_subset_df[feature_columns]\n",
    "    first_timepoint_subset_df = first_timepoint_subset_df.dropna(axis=0)\n",
    "    # fit the model to the first timepoint\n",
    "    _ = pca_model.fit_transform(first_timepoint_subset_df)\n",
    "\n",
    "    # get the rest of the data fo transformation\n",
    "    df = df.drop(metadata_columns, axis=1)\n",
    "    df = df[feature_columns]\n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    metadata_df = metadata_df.loc[df.index]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    metadata_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # apply the model to the rest of the data\n",
    "    pca_embeddings = pca_model.transform(df)\n",
    "    # create a dataframe with the pca fit and the metadata\n",
    "    pca_df = pd.DataFrame(pca_embeddings, columns=[\"PCA0\", \"PCA1\"])\n",
    "    # add the metadata to the dataframe\n",
    "    pca_df = pd.concat([pca_df, metadata_df], axis=1)\n",
    "\n",
    "    return pca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_of_feature_sets = {\n",
    "    \"single-cell_profiles\": {\n",
    "        \"CP\": pathlib.Path(\n",
    "            \"../../data/CP_feature_select/profiles/features_selected_profile.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"scDINO\": pathlib.Path(\n",
    "            \"../../data/scDINO/CLS_features_annotated_normalized_feature_selected.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"CP_scDINO\": pathlib.Path(\n",
    "            \"../../data/CP_scDINO_features/combined_CP_scDINO_norm_fs.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "    },\n",
    "    \"bulk_profiles\": {\n",
    "        \"CP\": pathlib.Path(\n",
    "            \"../../data/CP_aggregated/profiles/aggregated_profile.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"scDINO\": pathlib.Path(\n",
    "            \"../../data/scDINO/CLS_features_annotated_normalized_feature_selected_aggregated.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "        \"CP_scDINO\": pathlib.Path(\n",
    "            \"../../data/CP_scDINO_features/combined_CP_scDINO_norm_fs_aggregated.parquet\"\n",
    "        ).resolve(strict=True),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for profile_level in dictionary_of_feature_sets.keys():\n",
    "    for profile in dictionary_of_feature_sets[profile_level].keys():\n",
    "        profile_df = pd.read_parquet(dictionary_of_feature_sets[profile_level][profile])\n",
    "        metadata_columns = [x for x in profile_df.columns if \"Metadata_\" in x]\n",
    "        feature_columns = [x for x in profile_df.columns if \"Metadata_\" not in x]\n",
    "        pca_df = fit_pca_to_the_first_timepoint(\n",
    "            profile_df,\n",
    "            timepoint_column=\"Metadata_Time\",\n",
    "            metadata_columns=metadata_columns,\n",
    "            feature_columns=feature_columns,\n",
    "            pca_model=pca_model,\n",
    "        )\n",
    "        # set the save path of the pca data\n",
    "        pca_save_path = pathlib.Path(\n",
    "            f\"../results/pca/{profile_level}_{profile}_pca.parquet\"\n",
    "        ).resolve()\n",
    "        pca_save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        # save the pca data\n",
    "        pca_df.to_parquet(pca_save_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timelapse_analaysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
